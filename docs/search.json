[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Statistical Methods (Fall 2023)",
    "section": "",
    "text": "Week\nDate\nTopics\nLecture\nReading\n\n\n\n\n1\n9/5\nIntroduction & History of Bayes Theorem\nSlide\n\n\n\n2\n9/12\nOne-parameter Models; Conjugate Priors\nSlide\nHoff Ch. 1-3, BC Ch. 1\n\n\n3\n9/19\nPrior Information and Prior Distribution\n\nBC Ch. 3\n\n\n4\n9/26\nDecision Theory and Bayesian Estimation\n\nBC Ch. 2, 4\n\n\n5\n10/3\nConnections to non-Bayesian Analysis; Hierarchical Models\n\nBDA Ch. 4, 5\n\n\n6\n10/10\nNo class (National Holiday)\n\n\n\n\n7\n10/17\nTesting and Model Comparison\n\nBC Ch. 5, 7, BDA Ch. 6, 7\n\n\n8\n10/24\nProject Proposal\n\n\n\n\n9\n10/31\nMetropolis-Hastings algorithms; Gibbs sampler\n\nBDA Ch. 10-11\n\n\n10\n11/7\nHamiltonian Monte Carlo; Variational Inference\n\nBDA Ch. 12-13\n\n\n11\n11/14\nBayesian regression\n\nBDA Ch. 14\n\n\n12\n11/21\nGeneralized Linear Models; Latent Variable Model\n\nBDA Ch. 16, 18\n\n\n13\n11/28\nEmpirical Bayes\n\nBC Ch. 10\n\n\n14\n12/5\nBayesian Nonparametrics\n\nBDA Ch. 21, 23\n\n\n15\n12/12\nFinal Project Presentation\n\n\n\n\n16\n12/19\nFinal Project Presentation"
  },
  {
    "objectID": "index.html#course-schedule",
    "href": "index.html#course-schedule",
    "title": "Bayesian Statistical Methods (Fall 2023)",
    "section": "",
    "text": "Week\nDate\nTopics\nLecture\nReading\n\n\n\n\n1\n9/5\nIntroduction & History of Bayes Theorem\nSlide\n\n\n\n2\n9/12\nOne-parameter Models; Conjugate Priors\nSlide\nHoff Ch. 1-3, BC Ch. 1\n\n\n3\n9/19\nPrior Information and Prior Distribution\n\nBC Ch. 3\n\n\n4\n9/26\nDecision Theory and Bayesian Estimation\n\nBC Ch. 2, 4\n\n\n5\n10/3\nConnections to non-Bayesian Analysis; Hierarchical Models\n\nBDA Ch. 4, 5\n\n\n6\n10/10\nNo class (National Holiday)\n\n\n\n\n7\n10/17\nTesting and Model Comparison\n\nBC Ch. 5, 7, BDA Ch. 6, 7\n\n\n8\n10/24\nProject Proposal\n\n\n\n\n9\n10/31\nMetropolis-Hastings algorithms; Gibbs sampler\n\nBDA Ch. 10-11\n\n\n10\n11/7\nHamiltonian Monte Carlo; Variational Inference\n\nBDA Ch. 12-13\n\n\n11\n11/14\nBayesian regression\n\nBDA Ch. 14\n\n\n12\n11/21\nGeneralized Linear Models; Latent Variable Model\n\nBDA Ch. 16, 18\n\n\n13\n11/28\nEmpirical Bayes\n\nBC Ch. 10\n\n\n14\n12/5\nBayesian Nonparametrics\n\nBDA Ch. 21, 23\n\n\n15\n12/12\nFinal Project Presentation\n\n\n\n\n16\n12/19\nFinal Project Presentation"
  },
  {
    "objectID": "index.html#important-dates",
    "href": "index.html#important-dates",
    "title": "Bayesian Statistical Methods (Fall 2023)",
    "section": "Important Dates:",
    "text": "Important Dates:\n\n10/10: No class (National Holiday)\n10/24: Project proposal: you need to prepare a 10-min presentation for your project proposal\n12/12,19: Final project presentation: a 20-min presentation for your final project"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "BDA Book Website\nStan"
  },
  {
    "objectID": "resources.html#links",
    "href": "resources.html#links",
    "title": "Resources",
    "section": "",
    "text": "BDA Book Website\nStan"
  },
  {
    "objectID": "slides/01-intro.html#course-description",
    "href": "slides/01-intro.html#course-description",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Course Description",
    "text": "Course Description\n\nStatistical analysis is an inversion process: retrieving the causes (models/parameters) from the effects (observations/sample/data)\nBayes’ Theorem: If \\(A\\) and \\(E\\) are events such that \\(\\P(E) \\neq 0\\), \\[\\P(A \\mid E)=\\frac{\\P(E \\mid A) \\P(A)}{\\P(E \\mid A) \\P(A)+\\P\\left(E \\mid\nA^c\\right) \\P\\left(A^c\\right)}.\\]\nLet \\(A\\) be causes and \\(E\\) be effects. Bayes’ Theorem gives the relationship between \\(\\P(A\\mid E)\\) (statistical inference) and \\(\\P(E\\mid A)\\) (phenomenon).\nThis course will focus on statistical analysis under the Bayesian paradigm."
  },
  {
    "objectID": "slides/01-intro.html#course-description-1",
    "href": "slides/01-intro.html#course-description-1",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Course Description",
    "text": "Course Description\n\n\nAdapting Bayes’ Theorem to a parametric problem,\n\n\\[\\pi(\\theta|x) = \\frac{p(x|\\theta)\\pi(\\theta)}{\\int\n    p(x|\\theta^{\\prime})\\pi(\\theta^{\\prime})d\\theta^{\\prime}}.\\]\n\\[\\begin{align*}\n\\theta        & \\longleftrightarrow \\text{parameter}\\\\\nx             & \\longleftrightarrow \\text{data}\\\\\n\\pi(\\theta)   & \\longleftrightarrow \\textcolor{magenta}{\\text{prior distribution}}\\\\\np(x|\\theta)   & \\longleftrightarrow \\text{likelihood/model}\\\\\n\\pi(\\theta|x) & \\longleftrightarrow \\textcolor{magenta}{\\text{posterior distribution}}\\\\\n\\end{align*}\\] \n\nKey components: priors and posteriors"
  },
  {
    "objectID": "slides/01-intro.html#course-description-2",
    "href": "slides/01-intro.html#course-description-2",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Course Description",
    "text": "Course Description\nA general procedure for Bayesian statistical analysis:\n\nChoose a class \\(\\mc{M}\\) of models for the sample \\(x\\);\nChoose a prior distribution over \\(\\mc{M}\\);\nUse Bayes Theorem to compute the posterior distribution of models given the sample;\nPick a “good” model based on the posterior distribution."
  },
  {
    "objectID": "slides/01-intro.html#topics",
    "href": "slides/01-intro.html#topics",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Topics",
    "text": "Topics\n\n\nPrinciples for the choice of priors\nInference based on the posterior\nBayesian analysis for different problems:\n\nestimation\nhypothesis testing\nregression\nprediction\nnonparametric model\nmodel comparison"
  },
  {
    "objectID": "slides/01-intro.html#course-materials",
    "href": "slides/01-intro.html#course-materials",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Course Materials",
    "text": "Course Materials\n\n\nHoff, P. D. (2009). A First Course in Bayesian Statistical Methods.\nRobert, C. P. (2007). The Bayesian Choice, 2nd Edition.\nGelman, A. et al. (2020). Bayesian Data Analysis, 3rd Edition.\nRobert, C. P., & Casella, G. (2004). Monte Carlo Statistical Methods, 2nd Edition.\nProf. Rebecca Steorts at Duke. Lecture notes\nSlides will be posted on NTU Cool."
  },
  {
    "objectID": "slides/01-intro.html#course-schedule",
    "href": "slides/01-intro.html#course-schedule",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Course Schedule",
    "text": "Course Schedule\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nTopics\nReading\n\n\n\n\n1\n9/5\nIntroduction & History of Bayes Theorem\n\n\n\n2\n9/12\nOne-parameter Models; Conjugate Priors\nHoff Ch. 1-3, BC Ch. 1\n\n\n3\n9/19\nPrior Information and Prior Distribution\nBC Ch. 3\n\n\n4\n9/26\nDecision Theory and Bayesian Estimation\nBC Ch. 2, 4\n\n\n5\n10/3\nConnections to non-Bayesian Analysis; Hierarchical Models\nBDA Ch. 4, 5\n\n\n6\n10/10\nNo class (National Holiday)\n\n\n\n7\n10/17\nTesting and Model Comparison\nBC Ch. 5, 7, BDA Ch. 6, 7\n\n\n8\n10/24\nProject Proposal\n\n\n\n9\n10/31\nMetropolis-Hastings algorithms; Gibbs sampler\nBDA Ch. 10-11\n\n\n10\n11/7\nHamiltonian Monte Carlo; Variational Inference\nBDA Ch. 12-13\n\n\n11\n11/14\nBayesian regression\nBDA Ch. 14\n\n\n12\n11/21\nGeneralized Linear Models; Latent Variable Model\nBDA Ch. 16, 18\n\n\n13\n11/28\nEmpirical Bayes\nBC Ch. 10\n\n\n14\n12/5\nBayesian Nonparametrics\nBDA Ch. 21, 23\n\n\n15\n12/12\nFinal Project Presentation\n\n\n\n16\n12/19\nFinal Project Presentation"
  },
  {
    "objectID": "slides/01-intro.html#grading",
    "href": "slides/01-intro.html#grading",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Grading",
    "text": "Grading\n\n\nHomework (3 - 4 homeworks): 30%\nOral Presentation (project proposal and final presentation): 40%\nWritten Report: 30%\n\n\nContact information\n\n\nOffice: Room 602, Cosmology Hall\nE-mail: chunhaoy@ntu.edu.tw\nOffice Hours: Tue. 3-5pm or by appointment"
  },
  {
    "objectID": "slides/01-intro.html#final-project",
    "href": "slides/01-intro.html#final-project",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Final Project",
    "text": "Final Project\n\n\nA group of 2-3 students\nChoose a dataset and find a problem which you can answer with your dataset.\nFigure out how to perform legitimate statistical analysis based on (but not limited to) what we learn in this course.\nAn oral presentation of your results (20 mins per group)\nA written report (8 pages) including:\n\ndescription of the dataset\nstatistical problem\nmodel and inference\nresults and conclusion\nreference\n\nMore details will be announced after midterm exam."
  },
  {
    "objectID": "slides/01-intro.html#prerequisites",
    "href": "slides/01-intro.html#prerequisites",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Prerequisites",
    "text": "Prerequisites\n\n\nBasic calculus and linear algebra\nMathematical statistics (undergrad level is fine)\nFamiliarity with some data analytic programming language (R/Python/MATLAB)\nExperiences with data analysis is not required but will be helpful"
  },
  {
    "objectID": "slides/01-intro.html#example-8-school-dataset",
    "href": "slides/01-intro.html#example-8-school-dataset",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Example: 8-school dataset",
    "text": "Example: 8-school dataset\nA study was performed for the ETS to analyze the effects of special coaching programs on SAT scores. Eight schools with their own coaching programs were involved in this study.\n\n\n\n\n\nSchool\nEffect\nStd\n\n\n\n\nA\n28.39\n14.9\n\n\nB\n7.94\n10.2\n\n\nC\n-2.75\n16.3\n\n\nD\n6.82\n11.0\n\n\nE\n-0.64\n9.4\n\n\nF\n0.63\n11.4\n\n\nG\n18.01\n10.4\n\n\nH\n12.16\n17.6\n\n\n\n\n\n\n\n\n\nSee Ch 5.5 of BDA3."
  },
  {
    "objectID": "slides/01-intro.html#example-8-school-dataset-1",
    "href": "slides/01-intro.html#example-8-school-dataset-1",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Example: 8-school dataset",
    "text": "Example: 8-school dataset\nWhat can we ask about this dataset?\n\nIs there any difference between the coaching programs?\nWhich program is considered effective?\nWhich program is the most effective?\nHow much can we expect to improve on the SAT scores after taking the coaching programs?"
  },
  {
    "objectID": "slides/01-intro.html#step-1-2-determine-the-likelihood-and-prior",
    "href": "slides/01-intro.html#step-1-2-determine-the-likelihood-and-prior",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Step 1 & 2: Determine the likelihood and prior",
    "text": "Step 1 & 2: Determine the likelihood and prior\n\nConsider \\[\\begin{align*}\nY_{i} \\mid \\theta_i, \\sigma_i^2 & \\ind N(\\theta_i, \\sigma_i^2), i = 1,\\ldots, 8\\\\\n\\theta_i \\mid \\mu, \\tau & \\ind N(\\mu, \\tau^2)\n\\end{align*}\\] where \\(Y_i\\)’s are the observed average treatment effect and \\(\\sigma_i^2\\)’s are the variance of the treatment effects.\nWe are interested in estimating the \\(\\theta_i\\)’s, which are the effects of the coaching programs."
  },
  {
    "objectID": "slides/01-intro.html#step-4-inference-based-on-the-posterior",
    "href": "slides/01-intro.html#step-4-inference-based-on-the-posterior",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Step 4: Inference based on the posterior",
    "text": "Step 4: Inference based on the posterior\n\ndata {\n  int&lt;lower=0&gt; J;         \n  real y[J];              \n  real&lt;lower=0&gt; sigma[J];\n}\nparameters {\n  real mu;                \n  real&lt;lower=0&gt; tau;      \n  real theta[J];\n}\nmodel {\n  theta ~ normal(mu, tau); // prior\n  y ~ normal(theta, sigma); // likelihood\n}"
  },
  {
    "objectID": "slides/01-intro.html#step-4-inference-based-on-the-posterior-1",
    "href": "slides/01-intro.html#step-4-inference-based-on-the-posterior-1",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Step 4: Inference based on the posterior",
    "text": "Step 4: Inference based on the posterior\n\nlibrary(rstan)\nschools_dat &lt;- list(J = 8,\n    y = c(28, 8, -3, 7, -1, 1, 18, 12),\n    sigma = c(15, 10, 16, 11, 9, 11, 10, 18)) \nfit &lt;- rstan::sampling(school_model, data = schools_dat,\n    chains = 4, iter = 11000, warmup = 1000, thin = 10)"
  },
  {
    "objectID": "slides/01-intro.html#step-4-inference-based-on-the-posterior-2",
    "href": "slides/01-intro.html#step-4-inference-based-on-the-posterior-2",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Step 4: Inference based on the posterior",
    "text": "Step 4: Inference based on the posterior"
  },
  {
    "objectID": "slides/01-intro.html#stan-statistical-computing-platform",
    "href": "slides/01-intro.html#stan-statistical-computing-platform",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Stan: Statistical Computing Platform",
    "text": "Stan: Statistical Computing Platform\n\n\n\n\n\n\n\nProvide automated Bayesian computation\nInterface with R/Python/MATLAB/…"
  },
  {
    "objectID": "slides/01-intro.html#who-is-the-father-of-statistics",
    "href": "slides/01-intro.html#who-is-the-father-of-statistics",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Who is the father of statistics?",
    "text": "Who is the father of statistics?\nSome important statisticians:\n\nCarl Friedrich Gauss (1777 - 1855): Gaussian distribution, …\nRonald A. Fisher (1890 - 1962): likelihood based inference, …\nKarl Pearson (1857 - 1936): Pearson’s correlation coefficient, …\nWilliam Sealy Gosset (1876 - 1937): \\(t\\)-test and \\(t\\) distribution, …\nJerzy Neyman (1894 - 1981): Neyman-Pearson Lemma, …\nPierre-Simon Laplace (1749 - 1827): Central Limit Theorem, …\nThomas Bayes (1702 - 1761): Bayes Theorem, …"
  },
  {
    "objectID": "slides/01-intro.html#thomas-bayes",
    "href": "slides/01-intro.html#thomas-bayes",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Thomas Bayes",
    "text": "Thomas Bayes\n\n\n\nBritish Reverend Thomas Bayes (1702 - 1761)\nWork on inverse probability problem\nDiscover a relationship between causes and observations (1746 - 1749), which is later called Bayes Theorem\nWrite “An Essay towards solving a Problem in the Doctrine of Chances”\nHis philosopher friend, Richard Price, edited and published his result."
  },
  {
    "objectID": "slides/01-intro.html#bayes-thought-experiment",
    "href": "slides/01-intro.html#bayes-thought-experiment",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Bayes’ Thought Experiment",
    "text": "Bayes’ Thought Experiment"
  },
  {
    "objectID": "slides/01-intro.html#pierre-simon-laplace",
    "href": "slides/01-intro.html#pierre-simon-laplace",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Pierre-Simon Laplace",
    "text": "Pierre-Simon Laplace\n\n\n\nA French mathematician (1749 - 1827)\nDiscover the same rule in 1774, independent of Bayes\nUsing conditional probability, write down the rule as \\[\\begin{align*}\n\\P(A \\mid E)=\\frac{\\P(E \\mid A) \\P(A)}{\\P(E \\mid A) \\P(A)+\\P\\left(E \\mid\nA^c\\right) \\P\\left(A^c\\right)}.\n\\end{align*}\\]\nPropose to use equi-probability as the prior, i.e., the uniform prior"
  },
  {
    "objectID": "slides/01-intro.html#laplaces-rule-of-succession",
    "href": "slides/01-intro.html#laplaces-rule-of-succession",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Laplace’s Rule of Succession",
    "text": "Laplace’s Rule of Succession\n\nIf we repeat an experiment that we know can result in a success or failure, \\(n\\) times independently, and get \\(s\\) successes, and \\(n-s\\) failures, then what is the probability that the next repetition will succeed?\nLaplace’s Answer: \\[\\P\\left(X_{n+1}=1 \\mid X_1+\\cdots+X_n=s\\right)=\\frac{s+1}{n+2}\\]\nThis answer is obtained from the Beta-Binomial model."
  },
  {
    "objectID": "slides/01-intro.html#pierre-simon-laplace-1",
    "href": "slides/01-intro.html#pierre-simon-laplace-1",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Pierre-Simon Laplace",
    "text": "Pierre-Simon Laplace\n\nLaplace was not satisfied with the uniform prior, neither did other mathematicians.\nHowever, he still applied Bayes Theorem to solve many practical problems:\n\nEstimating the French population\nBirth and census study\nCredibility of witnesses in the court\n\nIn 1810, he announced the Central Limit Theorem.\nAt the age of 62, he turned to frequentist-based approach. Why?"
  },
  {
    "objectID": "slides/01-intro.html#decline-of-bayesian-statistics",
    "href": "slides/01-intro.html#decline-of-bayesian-statistics",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Decline of Bayesian Statistics",
    "text": "Decline of Bayesian Statistics\n\nThe subjective component, prior distribution, is heavily criticized by mathematicians and theorists.\nFor large dataset, Bayesian and frequentist produced almost the same result.\nDataset became more reliable, and frequentist approaches are easier to implement.\nBayesian approaches are computationally challenging, even for simple models.\nResearchers tend to design their own experiments to answer industrial/scientific questions."
  },
  {
    "objectID": "slides/01-intro.html#sir-ronald-a.-fisher",
    "href": "slides/01-intro.html#sir-ronald-a.-fisher",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Sir Ronald A. Fisher",
    "text": "Sir Ronald A. Fisher\n\n\n\nBritish Statistician/Mathematician (1890 - 1962)\nTea and milk experiment\nFather of modern statistics and experimental design\nProblem –&gt; Experiment –&gt; Data –&gt; Analysis\nDevelop a collection of statistical methods, e.g., MLE, ANOVA, Fisher information, sufficient statistics, etc."
  },
  {
    "objectID": "slides/01-intro.html#revival-of-bayesian-statistics",
    "href": "slides/01-intro.html#revival-of-bayesian-statistics",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Revival of Bayesian Statistics",
    "text": "Revival of Bayesian Statistics\n\nClean, reliable data -&gt; Frequentist\nThrough the use of prior information, Bayesian approaches are actually more powerful and flexible when handling complex datasets.\nAdvances in computing technologies\nReadings:\n\nLindley, D. V. (1975). The future of statistics: A Bayesian 21st century. Advances in Applied Probability, 7, 106-115.\nEfron, B. (1986). Why isn’t everyone a Bayesian? The American Statistician, 40(1), 1-5.\nEfron, B. (1998). R. A. Fisher in the 21st century. Statistical Science, 95-114."
  },
  {
    "objectID": "slides/01-intro.html#what-is-probability",
    "href": "slides/01-intro.html#what-is-probability",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "What is probability?",
    "text": "What is probability?\n\nFrequentist: Probability is the limit of relative frequency as the experiment repeats infinitely.\nBayesian: Probability reflects one’s belief.\nHowever, it doesn’t matter how you interpret probability because\n\n\n\n\n\n\n\n\n\n\nImage source: https://www.lacan.upc.edu/admoreWeb/2018/05/all-models-are-wrong-but-some-are-useful-george-e-p-box/"
  },
  {
    "objectID": "slides/01-intro.html#the-theory-that-would-not-die",
    "href": "slides/01-intro.html#the-theory-that-would-not-die",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "The Theory That Would Not Die",
    "text": "The Theory That Would Not Die\n\n\nFor more interesting stories about Bayesian statistics, check\n\n\n\n\n\n\n\nThere is a talk at Google given by the author Sharon McGrayne.\nhttps://www.lesswrong.com/posts/RTt59BtFLqQbsSiqd/a-history-of-bayes-theorem"
  },
  {
    "objectID": "slides/01-intro.html#probability",
    "href": "slides/01-intro.html#probability",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Probability",
    "text": "Probability\n\nThe value \\(\\P(E)\\) is the probability of the occurrence of event \\(E\\).\nLet \\(\\Omega\\) be the sample space, i.e., the space containing all possible outcomes.\nA probability \\(\\P\\) on \\(\\Omega\\) satisfies:\n\n\\(\\P(\\Omega) = 1\\)\n\\(\\P(E) \\geq 0\\) for any \\(E \\subset \\Omega\\)\n(countable additivity) \\(\\P(\\cup_{i=1}^{\\infty} E_i) = \\sum_{i=1}^\\infty \\P(E_i)\\) for pairwise disjoint \\(E_i\\)’s"
  },
  {
    "objectID": "slides/01-intro.html#conditional-probability",
    "href": "slides/01-intro.html#conditional-probability",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\n\nThe conditional probability of \\(A\\) given \\(B\\) is\n\n\\[\\P(A \\mid B) \\coloneqq \\frac{\\P(A \\cap B)}{\\P(B)}, \\quad \\text{if}\\;\\;\\P(B) &gt; 0.\\]\n\n\n\nOne-line proof of Bayes Theorem: If \\(\\P(A)\\) and \\(\\P(B)\\) are both non-zero,\n\n\\[\\P(A \\mid B) = \\frac{\\P(A \\cap B)}{\\P(B)} = \\frac{\\P(B \\mid A)\\P(A)}{\\P(B)}.\\]"
  },
  {
    "objectID": "slides/01-intro.html#random-variables",
    "href": "slides/01-intro.html#random-variables",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Random Variables",
    "text": "Random Variables\n\nA random variable is\n\na measurable function\nan outcome from a random experiment\n\nThe information about a random variable is given by it probability density function (pdf) or probability mass function (pmf).\npdf: \\(f(x) \\geq 0\\) and \\(\\int f(x) dx = 1\\)\npmf: \\(f(x) = \\P(X = x)\\) and \\(\\sum f(x) = 1\\)\nExpectation: \\(\\E(X) = \\int xf(x)dx\\) or \\(\\E(X) = \\sum x\\P(X = x)\\)\nVariance: \\(\\var(X) = \\E[(X - \\mu)^2] = \\E(X^2) - \\mu^2\\) where \\(\\mu = \\E(X)\\).\nCovariance: \\(\\cov(X, Y) = \\E[(X - \\mu_X)(Y - \\mu_Y)] = \\E(XY) - \\mu_X\\mu_Y\\)"
  },
  {
    "objectID": "slides/01-intro.html#independence",
    "href": "slides/01-intro.html#independence",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Independence",
    "text": "Independence\n\nIndependence of events: \\(\\P(A \\cap B) = \\P(A)\\P(B)\\)\nIndependent random variables:\n\n\\(\\Leftrightarrow\\) \\(f_{X,Y}(x, y) = f_X(x)f_Y(y)\\)\n\\(\\Rightarrow\\) \\(\\E(XY) = \\E(X) \\E(Y)\\) (the reverse is not true)\n\\(\\Leftrightarrow\\) \\(f_{X|Y}(x|y) = f_X(x)\\)\n\nConditional independence\n\n\\(X \\perp Y \\mid Z\\): given \\(Z\\), \\(X\\) and \\(Y\\) are independent\nEquivalently, \\(X \\mid Z\\) and \\(Y \\mid Z\\) are independent.\n\nRemark: (mutual) independence DOES NOT imply conditional independence\nExample: \\(X, Z \\iid \\text{Ber}(1/2)\\) and \\(Y = I(X \\neq Z)\\). Check that \\(X\\) and \\(Y\\) are independent, but they are not conditionally independent given \\(Z\\)."
  },
  {
    "objectID": "slides/01-intro.html#law-of-total-probabilityexpectationvariance",
    "href": "slides/01-intro.html#law-of-total-probabilityexpectationvariance",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Law of Total Probability/Expectation/Variance",
    "text": "Law of Total Probability/Expectation/Variance\n\n\nLaw of Total Probability: For \\(B_i \\cap B_j = \\emptyset\\) and \\(\\cup_{i=1}^k B_i = \\Omega\\),\n\n\\[\\P(A) = \\sum_{i=1}^k \\P(A \\mid B_i)\\P(B_i).\\]\n\n\n\nLaw of Total Expectation (tower property/double expectation):\n\n\\[\\E(X) = \\E_Y(\\E_{X|Y}(X|Y)).\\]\n\n\n\nLaw of Total Variance:\n\n\\[\\var(X) = \\var(\\E(X|Y)) + \\E(\\var(X|Y)).\\]"
  },
  {
    "objectID": "slides/01-intro.html#important-univariate-distributions",
    "href": "slides/01-intro.html#important-univariate-distributions",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Important univariate distributions",
    "text": "Important univariate distributions\n\n\nContinuous univariate distribution:\n\nNormal distribution (on \\(\\R\\))\nGamma distribution (on \\(\\R_+\\))\nBeta distribution (on \\([0, 1]\\))\n\nDiscrete univariate distribution:\n\nBinomial distribution (on \\(\\{0, 1, \\ldots, n\\}\\))\nPoisson distribution (on \\(\\{0, 1, 2, \\ldots\\}\\))\nNegative Binomial distribution (on \\(\\{0, 1, 2, \\ldots\\}\\))"
  },
  {
    "objectID": "slides/01-intro.html#normal-distribution",
    "href": "slides/01-intro.html#normal-distribution",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Normal Distribution",
    "text": "Normal Distribution\n\n\n\\(N(\\mu, \\sigma^2)\\), \\(\\mu \\in \\R\\), \\(\\sigma &gt; 0\\)\nDensity function:\n\n\\[f(x;\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right), \\quad x \\in \\R\\]\n\n\\(\\E(X) = \\mu\\) and \\(\\var(X) = \\sigma^2\\)"
  },
  {
    "objectID": "slides/01-intro.html#gamma-distribution",
    "href": "slides/01-intro.html#gamma-distribution",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\n\n\\(\\text{Gamma}(\\alpha, \\beta)\\), \\(\\alpha, \\beta &gt; 0\\)\nDensity function:\n\n\\[f(x;\\alpha, \\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha-1}\\exp(-\\beta x), \\quad x &gt; 0\\]\n\n\\(\\E(X) = \\frac{\\alpha}{\\beta}\\) and \\(\\var(X) = \\frac{\\alpha}{\\beta^2}\\).\nSpecial Case: Exponential distribution (\\(\\alpha = 1\\)) and \\(\\chi^2\\) distribution (\\(\\alpha = k/2\\) and \\(\\beta = \\frac{1}{2}\\), where \\(k\\) is the degree of freedom)"
  },
  {
    "objectID": "slides/01-intro.html#beta-distribution",
    "href": "slides/01-intro.html#beta-distribution",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Beta Distribution",
    "text": "Beta Distribution\n\n\n\\(\\text{Beta}(\\alpha, \\beta)\\), \\(\\alpha, \\beta &gt; 0\\)\nDensity function:\n\n\\[f(x;\\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}x^{\\alpha-1}(1-x)^{\\beta-1}, \\quad 0 \\leq x \\leq 1\\]\n\n\\(B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}\\) is the Beta function\n\\(\\E(X) = \\frac{\\alpha}{\\alpha+\\beta}\\)\nSpecial case: Uniform distribution (\\(\\alpha = \\beta = 1\\))"
  },
  {
    "objectID": "slides/01-intro.html#binomial-distribution",
    "href": "slides/01-intro.html#binomial-distribution",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\n\n\\(\\text{Bin}(n, p)\\), \\(n \\in \\mathbb{N}\\), \\(0 &lt; p &lt; 1\\)\nNumber of positive outcomes out of \\(n\\) binary trials\nMass function:\n\n\\[f(x; n, p) = \\choose{n}{x}p^x(1-p)^{n-x}, \\quad x = 0, 1,\\ldots, n\\]\n\n\\(\\E(X) = np\\) and \\(\\var(X) = np(1-p)\\)\nSpecial case: Bernoulli distribution (\\(n = 1\\))"
  },
  {
    "objectID": "slides/01-intro.html#poisson-distribution",
    "href": "slides/01-intro.html#poisson-distribution",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Poisson Distribution",
    "text": "Poisson Distribution\n\n\n\\(\\text{Poi}(\\lambda)\\), \\(\\lambda &gt; 0\\)\nMass function:\n\n\\[f(x;\\lambda) = \\frac{e^{-\\lambda}\\lambda^x}{x!}, \\quad x = 0, 1, 2, \\ldots\\]\n\n\\(\\E(X) = \\var(X) = \\lambda\\)."
  },
  {
    "objectID": "slides/01-intro.html#negative-binomial-distribution",
    "href": "slides/01-intro.html#negative-binomial-distribution",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\n\n\\(\\text{NB}(r, p)\\), \\(r = 1,2,\\ldots\\), \\(0 &lt; p &lt; 1\\)\nNumber of failures before the \\(r\\)th success\nMass function:\n\n\\[f(x;r,p) = \\choose{x+r-1}{x}p^r(1-p)^x, \\quad x = 0, 1, \\ldots\\]\n\n\\(\\E(X) = \\frac{r(1-p)}{p}\\) and \\(\\var(X) = \\frac{r(1-p)}{p^2}\\).\nSpecial case: Geometric distribution (\\(r=1\\), number of failures before the first success)"
  },
  {
    "objectID": "slides/01-intro.html#maximum-likelihood-estimation",
    "href": "slides/01-intro.html#maximum-likelihood-estimation",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Maximum Likelihood Estimation",
    "text": "Maximum Likelihood Estimation\n\nSuppose \\(X_1, \\ldots, X_n \\iid f(x|\\theta)\\).\nThe likelihood function is \\[L(\\theta) = \\prod_{i=1}^n f(x_i|\\theta).\\]\nThe MLE of \\(\\theta\\) is \\(\\hat{\\theta} = \\argmax_{\\theta}L(\\theta)\\).\nUnder some regularity conditions on \\(f(x|\\theta)\\), the MLE is efficient (has the smallest variance) and its distribution is approximately normal (when \\(n\\) is large enough)."
  },
  {
    "objectID": "slides/01-intro.html#law-of-large-numbers-central-limit-theorem",
    "href": "slides/01-intro.html#law-of-large-numbers-central-limit-theorem",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Law of Large Numbers & Central Limit Theorem",
    "text": "Law of Large Numbers & Central Limit Theorem\nSuppose \\(X_1, \\ldots, X_n\\) are iid (independent and identically distributed) from some distribution \\(F\\) with \\(\\E(X) = \\mu\\) and \\(\\var(X) = \\sigma^2 &lt; \\infty\\). Let \\(\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i\\). Then\n\nLaw of Large Numbers (LLN): \\(\\bar{X}_n\\) will be very closed to \\(\\mu\\) for large \\(n\\) \\[ \\bar{X}_n \\cas \\mu\\]\nCentral Limit Theorem (CLT): the distribution of \\(\\bar{X}_n\\) will be approximately normal for large \\(n\\) \\[\\sqrt{n}(\\bar{X}_n - \\mu) \\cd N(0, \\sigma^2)\\]"
  },
  {
    "objectID": "slides/01-intro.html#monte-carlo-approximationestimation",
    "href": "slides/01-intro.html#monte-carlo-approximationestimation",
    "title": "Lecture 01: Course Introduction and Review",
    "section": "Monte Carlo Approximation/Estimation",
    "text": "Monte Carlo Approximation/Estimation\n\nSuppose we have function \\(f: [a, b] \\to \\R\\) and we want to compute \\(I = \\int_a^b f(x)dx\\).\nWrite \\[I = (b-a)\\int_a^b f(x)\\frac{1}{b-a}dx = (b-a)\\E(f(X)), \\quad X \\sim \\text{Unif}(a,b).\\]\nMonte Carlo approximation:\n\nGenerate \\(X_1, \\ldots, X_n \\iid \\text{Unif}(a,b)\\).\nCompute \\(\\hat{I}_n = \\frac{b-a}{n}\\sum_{i=1}^n f(X_i)\\).\nBy LLN and CLT, \\[\\hat{I}_n \\cas I \\quad \\text{and} \\quad \\sqrt{n}(\\hat{I}_n - I) \\cd N(0, (b-a)^2\\sigma^2)\\] if \\(\\sigma^2 = \\var(f(X)) &lt; \\infty\\).\n\n\n\n\nHome"
  },
  {
    "objectID": "slides/02-intro-bayes.html#beta-binomial-model-1",
    "href": "slides/02-intro-bayes.html#beta-binomial-model-1",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Beta-Binomial model",
    "text": "Beta-Binomial model\n\nLet \\(X_1, \\ldots, X_n \\mid p \\iid \\ber(p)\\).\nConsider the prior \\(p \\sim \\text{Beta}(\\alpha, \\beta)\\) where \\(\\alpha\\) and \\(\\beta\\) are known.\nThe posterior distribution of \\(p\\) given \\(X_1, \\ldots, X_n\\) is \\[\np \\mid X_1, \\ldots, X_n \\sim \\text{Beta}\\left(\\alpha + \\sum_{i=1}^n X_i, \\beta + n - \\sum_{i=1}^n X_i \\right).\n\\]"
  },
  {
    "objectID": "slides/02-intro-bayes.html#derivation",
    "href": "slides/02-intro-bayes.html#derivation",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Derivation",
    "text": "Derivation\n\nBayes Theorem: \\[\\begin{align*}\n\\pi(p \\mid x) & = \\frac{f(x \\mid p) \\pi(p)}{\\int f(x \\mid p) \\pi(p) dp} = \\frac{\\text{likelihood} \\times \\text{prior}}{\\text{marginal}}\\\\\n& \\propto f(x \\mid p) \\pi(p) = \\text{likelihood} \\times \\text{prior}\n\\end{align*}\\]\nThe marginal (and other normalizing constants) can be ignored.\nThe likelihood is \\[\nf(x_1, \\ldots, x_n \\mid p) = \\prod_{i=1}^n p^{x_i}(1-p)^{1-x_i} = p^{\\sum_{i=1}^n x_i}(1-p)^{n - \\sum_{i=1}^n x_i}.\n\\]\nThe prior is \\[\n\\pi(p) = \\frac{1}{B(\\alpha, \\beta)} p^{\\alpha-1} (1-p)^{\\beta-1} \\propto p^{\\alpha-1}(1-p)^{\\beta - 1}.\n\\]"
  },
  {
    "objectID": "slides/02-intro-bayes.html#derivation-1",
    "href": "slides/02-intro-bayes.html#derivation-1",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Derivation",
    "text": "Derivation\n\nHence the posterior is \\[\\begin{align*}\n\\pi(p \\mid X_1, \\ldots, X_n) & \\propto p^{\\sum_{i=1}^n x_i}(1-p)^{n - \\sum_{i=1}^n x_i} \\times p^{\\alpha-1}(1-p)^{\\beta - 1}\\\\\n& = p^{\\alpha + \\sum_{i=1}^n x_i - 1}(1-p)^{\\beta + n - \\sum_{i=1}^n x_i - 1}.\n\\end{align*}\\]\nRecognizing that this is the kernel of a Beta distribution, the posterior is \\[\np \\mid X_1, \\ldots, X_n \\sim \\text{Beta}\\left(\\alpha + \\sum_{i=1}^n X_i, \\beta + n - \\sum_{i=1}^n X_i \\right).\n\\]\nIt’s called Beta-Binomial model since the posterior only depends on \\(\\sum X_i\\) and the distribution of \\(\\sum X_i\\) is \\(\\bin(n,p)\\)."
  },
  {
    "objectID": "slides/02-intro-bayes.html#kernel-of-a-pdfpmf",
    "href": "slides/02-intro-bayes.html#kernel-of-a-pdfpmf",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Kernel of a pdf/pmf",
    "text": "Kernel of a pdf/pmf\n\nThe kernel is the form of the pdf or pmf in which any factors that are not functions of any of the variables in the domain are omitted.\nExamples:\n\n\nNormal: \\(\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\\)\nGamma: \\(x^{\\alpha-1}\\exp(-\\beta x)\\)\nBeta: \\(x^{\\alpha-1}(1-x)^{\\beta-1}\\)\nPoisson: \\(\\frac{\\lambda^x}{x!}\\)\n\n\nWe can use only the kernels to simplify the computation."
  },
  {
    "objectID": "slides/02-intro-bayes.html#posterior-distribution",
    "href": "slides/02-intro-bayes.html#posterior-distribution",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Posterior Distribution",
    "text": "Posterior Distribution\n\nset.seed(2023)\nn &lt;- 15\np &lt;- 0.3\nX &lt;- rbinom(n, 1, p)\ns &lt;- sum(X)\np_mle &lt;- s/n # MLE\nprint(X)\n\n [1] 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n\n\n\nlibrary(ggplot2)\nggplot(data = data.frame(p = c(0, 1)), aes(p)) + \n    lims(x = c(0, 1), y = c(0, 5)) + \n    labs(x = \"p\", y = \"Density\") +\n    geom_function(fun = dunif, aes(col = \"blue\")) + \n    geom_function(fun = dbeta, aes(col = \"red\"), \n                  args = list(shape1 = s + 1, shape2 = n - s + 1)) + \n    geom_vline(xintercept = p_mle, linetype = \"dashed\", col = \"darkgrey\") + \n    geom_vline(xintercept = p, linetype = \"dashed\", col = \"darkgreen\") + \n    scale_colour_manual(name = \"Distribution\", \n                        values = c(\"blue\", \"red\"),\n                        labels = c(\"Prior\", \"Posterior\"))"
  },
  {
    "objectID": "slides/02-intro-bayes.html#posterior-distribution-output",
    "href": "slides/02-intro-bayes.html#posterior-distribution-output",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Posterior Distribution",
    "text": "Posterior Distribution"
  },
  {
    "objectID": "slides/02-intro-bayes.html#posterior-inference",
    "href": "slides/02-intro-bayes.html#posterior-inference",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Posterior Inference",
    "text": "Posterior Inference\n\nThe posterior distribution of \\(p\\) contains much more information than the MLE.\nWe can use the posterior for:\n\nEstimation: \\(\\hat{p} = \\E(p \\mid X_1, \\ldots, X_n)\\) (posterior mean)\nPrediction: \\(\\P(X_{n+1} = 1 \\mid X_1, \\ldots, X_n)\\)\nInterval estimation: Find \\((L, U)\\) such that \\(\\P(L \\leq p \\leq U \\mid X_1, \\ldots, X_n) = 0.95\\)\n\nIn the Beta-Binomial model, an estimate for \\(p\\) is \\[\n\\hat{p} = \\E(p \\mid X_1, \\ldots, X_n) = \\frac{\\alpha + \\sum_{i=1}^n X_i}{\\alpha + \\beta + n}\n\\] whereas the MLE is \\(\\hat{p}_{\\text{MLE}} = \\frac{1}{n}\\sum_{i=1}^nX_i\\)."
  },
  {
    "objectID": "slides/02-intro-bayes.html#maximum-a-posteriori-estimate",
    "href": "slides/02-intro-bayes.html#maximum-a-posteriori-estimate",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Maximum-a-posteriori Estimate",
    "text": "Maximum-a-posteriori Estimate\n\nThe posterior mean is not the only estimate we can obtain from the posterior.\nAnother commonly used estimator is the maximum-a-posterior (MAP) estimate \\[\n\\hat{p}_{\\text{MAP}} = \\argmax_{0 &lt; p &lt; 1} \\pi(p \\mid X_1, \\ldots, X_n).\n\\]\nSince the mode of \\(\\text{Beta}(\\alpha, \\beta)\\) is \\(\\frac{\\alpha-1}{\\alpha+\\beta-2}\\) when \\(\\alpha, \\beta &gt; 1\\), \\[\n\\hat{p}_{\\text{MAP}} = \\frac{\\alpha -1 + \\sum_{i=1}^n X_i}{\\alpha + \\beta + n - 2}.\n\\]\nIf \\(\\alpha = \\beta = 1\\) and \\(\\sum X_i &gt; 1\\), then \\(\\hat{p}_{\\text{MAP}} = \\hat{p}_{\\text{MLE}} = \\bar{X}\\)."
  },
  {
    "objectID": "slides/02-intro-bayes.html#recall-laplaces-rule-of-succession",
    "href": "slides/02-intro-bayes.html#recall-laplaces-rule-of-succession",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Recall: Laplace’s Rule of Succession",
    "text": "Recall: Laplace’s Rule of Succession\nGiven binary iid random variables \\(X_1, \\ldots, X_n\\) with \\(\\sum_{i=1}^n X_i = s\\), then \\[\\P\\left(X_{n+1}=1 \\mid X_1+\\cdots+X_n=s\\right)=\\frac{s+1}{n+2}.\\]\nDerivation:\n\nLet \\(X_1, \\ldots, X_n \\iid \\ber(p)\\) and \\(p \\sim \\text{Beta}(1,1)\\) (the uniform prior).\nThe posterior is \\(p \\mid X_1 + \\cdots + X_n = s \\sim \\text{Beta}(s + 1, n-s + 1)\\).\nAssuming \\(X_{n+1} \\sim \\ber(p)\\) and \\(X_i\\)’s are iid conditioned on \\(p\\), \\[\\begin{align*}\n\\P\\left(X_{n+1}=1 \\mid \\sum X_i=s\\right)\n& = \\int \\P(X_{n+1}=1 \\mid p)\\pi\\left(p \\mid \\sum X_i = s\\right) dp\\\\\n& = \\int p \\pi\\left(p \\mid \\sum X_i = s\\right) dp\n= \\frac{s+1}{n+2}.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/02-intro-bayes.html#interval-estimation-credible-intervalregion",
    "href": "slides/02-intro-bayes.html#interval-estimation-credible-intervalregion",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Interval Estimation: Credible Interval/Region",
    "text": "Interval Estimation: Credible Interval/Region\n\nFor frequentists, it’s called confidence interval/region.\nLet \\([L(X), U(X)]\\) be an interval for \\(\\theta\\) based on sample \\(X\\).\n\\(100\\times(1-\\alpha)\\%\\) Bayesian Coverage: \\(\\P(L(x) \\leq \\theta \\leq U(x) \\mid {\\color{magenta}X = x}) = 1-\\alpha\\).\n\ndescribes your information about the location of the true value of \\(\\theta\\) after you have observed \\(X = x\\)\n\n\\(100\\times(1-\\alpha)\\%\\) Frequentist Coverage: \\(\\P(L(X) \\leq \\theta \\leq U(X) \\mid {\\color{magenta}\\theta}) = 1-\\alpha\\)\n\ndescribes the probability that the interval will cover the true value before the data are observed\n\nThere are many ways to construct a credible interval:\n\nQuantile-based method\nHighest posterior density (HPD) region"
  },
  {
    "objectID": "slides/02-intro-bayes.html#quantile-based-method",
    "href": "slides/02-intro-bayes.html#quantile-based-method",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Quantile-based method",
    "text": "Quantile-based method\nTo find a \\(100\\times(1-\\alpha)\\%\\) credible interval for \\(\\theta\\):\n\nFind numbers \\(\\theta_{\\alpha / 2} &lt; \\theta_{1-\\alpha / 2}\\) such that\n\n\n\\(\\P\\left(\\theta&lt;\\theta_{\\alpha/2} \\mid X = x\\right)=\\alpha / 2\\);\n\\(\\P\\left(\\theta&gt;\\theta_{1-\\alpha / 2} \\mid X = x\\right)=\\alpha / 2\\).\n\n\nThe numbers \\(\\theta_{\\alpha / 2}, \\theta_{1-\\alpha / 2}\\) are the \\(\\alpha / 2\\) and \\(1-\\alpha / 2\\) posterior quantiles of \\(\\theta\\), and so \\[\\begin{align*}\n\\P\\left(\\theta \\in\\left[\\theta_{\\alpha / 2}, \\theta_{1-\\alpha / 2}\\right] \\mid X = x\\right) & =1-\\P\\left(\\theta \\notin\\left[\\theta_{\\alpha / 2}, \\theta_{1-\\alpha / 2}\\right] \\mid X = x\\right) \\\\\n& =1-\\left[\\P\\left(\\theta&lt;\\theta_{\\alpha / 2} \\mid X=x\\right)\\right.\\\\\n& \\qquad \\left.+\\P\\left(\\theta&gt;\\theta_{1-\\alpha / 2} \\mid X = x\\right)\\right] \\\\\n& =1-\\alpha.\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/02-intro-bayes.html#binomial-example",
    "href": "slides/02-intro-bayes.html#binomial-example",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Binomial Example",
    "text": "Binomial Example\nSuppose we observed \\(X=2\\) from a \\(\\bin(10, p)\\). Assume the uniform prior \\(p\\).\n\nalpha &lt;- 1; beta &lt;- 1 # uniform prior\nn &lt;- 10; X &lt;- 2 # data\n\nqbeta(c(0.025, 0.975), alpha + X, beta + n - X)\n\n[1] 0.06021773 0.51775585"
  },
  {
    "objectID": "slides/02-intro-bayes.html#highest-posterior-density-hpd-region",
    "href": "slides/02-intro-bayes.html#highest-posterior-density-hpd-region",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Highest posterior density (HPD) region",
    "text": "Highest posterior density (HPD) region\n\nDefinition 1 A \\(100 \\times(1-\\alpha) \\%\\) HPD region consists of a subset of the parameter space, \\(s(x) \\subset \\Theta\\) such that\n\n\\(\\P(\\theta \\in s(x) \\mid X = x)=1-\\alpha\\);\nIf \\(\\theta_a \\in s(x)\\), and \\(\\theta_b \\notin s(x)\\), then \\(\\pi\\left(\\theta_a \\mid X=x\\right)&gt;\\pi\\left(\\theta_b \\mid X=x\\right)\\).\n\n\n\nAn HPD region might not be an interval if the posterior density is multimodal (having multiple peaks)."
  },
  {
    "objectID": "slides/02-intro-bayes.html#binomial-example-1",
    "href": "slides/02-intro-bayes.html#binomial-example-1",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Binomial Example",
    "text": "Binomial Example\nLet’s compute the HPD for the previous example: \\(\\theta \\mid X = 2 \\sim \\text{Beta}(3, 9)\\).\n\nlibrary(HDInterval)\nhdi(qbeta, 0.95, shape1 = 3, shape2 = 9)\n\n     lower      upper \n0.04055517 0.48372366 \nattr(,\"credMass\")\n[1] 0.95\n\n\nThe HPD is narrower than the quantile-based interval.\n\n\n\n\nFig. 3.6 in Hoff’s book"
  },
  {
    "objectID": "slides/02-intro-bayes.html#wrap-up-for-the-beta-binomial-model",
    "href": "slides/02-intro-bayes.html#wrap-up-for-the-beta-binomial-model",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Wrap-up for the Beta-Binomial model",
    "text": "Wrap-up for the Beta-Binomial model\n\nThe Beta-Binomial model: \\[\\begin{align*}\nX \\mid p & \\sim \\bin(n,p)\\\\\np & \\sim \\text{Beta}(\\alpha,\\beta)\\\\\np \\mid X & \\sim \\text{Beta}(\\alpha + X, \\beta + n - X)\n\\end{align*}\\]\nNote that the posterior is in the same family of the prior: both of them are in the Beta family.\nIn this case, the Beta prior is called a conjugate prior for the Binomial model."
  },
  {
    "objectID": "slides/02-intro-bayes.html#catalog-for-conjugate-priors",
    "href": "slides/02-intro-bayes.html#catalog-for-conjugate-priors",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Catalog for conjugate priors",
    "text": "Catalog for conjugate priors\n\n\n\n\n\n\n\n\n\n\n\n\n\nSampling model\nParameter\nPrior\nPosterior\n\n\n\n\n\\(X \\sim \\bin(n, p)\\)\n\\(p\\)\n\\(\\text{Beta}(\\alpha_0, \\beta_0)\\)\n\\(\\text{Beta}(\\alpha_0 + X, \\beta_0+n-X)\\)\n\n\n\\(X \\sim N(\\mu, \\sigma^2)\\)\n\\(\\mu\\)\n\\(N(\\mu_0, \\sigma_0^2)\\)\n\\(N\\left(\\frac{1}{\\frac{1}{\\sigma_0^2}+\\frac{1}{\\sigma^2}}\\left(\\frac{\\mu_0}{\\sigma_0^2}+\\frac{ X}{\\sigma^2}\\right),\\left(\\frac{1}{\\sigma_0^2}+\\frac{1}{\\sigma^2}\\right)^{-1}\\right)\\)\n\n\n\\(X \\sim \\text{Poisson}(\\lambda)\\)\n\\(\\lambda\\)\n\\(\\text{Gamma}(\\alpha_0, \\beta_0)\\)\n\\(\\text{Gamma}(\\alpha_0 + X, \\beta_0+1)\\)\n\n\n\\(X \\sim \\text{Gamma}(\\alpha, \\beta)\\)\n\\(\\beta\\)\n\\(\\text{Gamma}(\\alpha_0, \\beta_0)\\)\n\\(\\text{Gamma}(\\alpha_0 + \\alpha, \\beta_0+X)\\)\n\n\n\\(X \\sim \\text{NB}(r, p)\\)\n\\(p\\)\n\\(\\text{Beta}(\\alpha_0, \\beta_0)\\)\n\\(\\text{Beta}(\\alpha_0 + r, \\beta_0+X)\\)\n\n\n\n\nMore can be found on Wiki\nExercise: Derive the posterior for the Normal-Normal model."
  },
  {
    "objectID": "slides/02-intro-bayes.html#real-data-example",
    "href": "slides/02-intro-bayes.html#real-data-example",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Real Data Example",
    "text": "Real Data Example\n\n\n2022年，基隆市男女嬰出生數分別為856及731，性別比例為1.1711（生下男嬰機率為0.5394）。\n同年，全台灣男女嬰出生數分別為71,208及66,205，性別比例為1.076（生下男嬰機率為0.5183）\n根據統計，全球人類自然出生性別比1.052（生下男嬰機率為0.5122）。\n基隆市自然出生性別比是否高於台灣平均？\n\n\n\n\n性別比 ＝ 男嬰數/女嬰數；生下男嬰機率 ＝ 男嬰數/(男嬰數+女嬰數)；生下男嬰機率 ＝ 性別比/(1+性別比)\n行政院資料庫Our World in Data"
  },
  {
    "objectID": "slides/02-intro-bayes.html#real-data-example-1",
    "href": "slides/02-intro-bayes.html#real-data-example-1",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Real Data Example",
    "text": "Real Data Example\n\nlibrary(tidyverse)\nlibrary(knitr)\n\nm &lt;- 856; f &lt;- 731\nprior_mean &lt;- c(0.5, 0.5122, 0.5122, 0.5122, 0.5122, 0.5122)\nalpha_plus_beta &lt;- c(2, 2, 10, 100, 1000, 10000)\nalpha &lt;- prior_mean * alpha_plus_beta\nbeta &lt;- alpha_plus_beta - alpha\n\n\ndata.frame(alpha, beta, prior_mean) |&gt; \n    mutate(alpha_plus_beta = alpha + beta,\n           post_mean = (alpha+m)/(alpha+beta+m+f),\n           ratio = post_mean/(1-post_mean),\n           post_int = paste0(\"[\", round(qbeta(0.025, alpha + m, beta + f), 3),\n                             \", \", round(qbeta(0.975, alpha + m, beta + f), 3), \"]\")) |&gt;\n    select(c(prior_mean, alpha_plus_beta, post_mean, ratio, post_int)) |&gt;\n    kable(format = \"markdown\", digits = 4,\n          col.names = c(\"Prior mean $\\\\frac{\\\\alpha}{\\\\alpha+\\\\beta}$\",\n                        \"$\\\\alpha + \\\\beta$\",\n                        \"Post. mean\", \"Gender ratio\",\n                        \"Post. 95% Interval\"))"
  },
  {
    "objectID": "slides/02-intro-bayes.html#real-data-example-1-output",
    "href": "slides/02-intro-bayes.html#real-data-example-1-output",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Real Data Example",
    "text": "Real Data Example\n\n\n\n\n\n\n\n\n\n\n\nPrior mean \\(\\frac{\\alpha}{\\alpha+\\beta}\\)\n\\(\\alpha + \\beta\\)\nPost. mean\nGender ratio\nPost. 95% Interval\n\n\n\n\n0.5000\n2\n0.5393\n1.1708\n[0.515, 0.564]\n\n\n0.5122\n2\n0.5393\n1.1708\n[0.515, 0.564]\n\n\n0.5122\n10\n0.5392\n1.1702\n[0.515, 0.564]\n\n\n0.5122\n100\n0.5378\n1.1634\n[0.514, 0.562]\n\n\n0.5122\n1000\n0.5289\n1.1226\n[0.51, 0.548]\n\n\n0.5122\n10000\n0.5159\n1.0658\n[0.507, 0.525]"
  },
  {
    "objectID": "slides/02-intro-bayes.html#some-follow-up-questions",
    "href": "slides/02-intro-bayes.html#some-follow-up-questions",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Some follow-up questions",
    "text": "Some follow-up questions\n\nIs the sample size (856+731=1587) large enough?\nWhich prior? Depend on how strong your prior belief is.\n\nNo prior knowledge \\(\\Rightarrow\\) Uniform prior\nReliable prior information \\(\\Rightarrow\\) prior with larger \\(\\alpha+\\beta\\)\n\nWith prior information, we can obtain better estimates when the sample size is small:\n\nFor example, think of a really small village in which only two boys and one girl were born last year.\nIf we don’t use any prior information, the gender ratio is 2.\n\nWhat if our prior information cannot be described by a Beta distribution?\n\nEx: our prior information indicates a multimodal distribution\nThe posterior will be complicated and we need some other methods for posterior inference."
  },
  {
    "objectID": "slides/02-intro-bayes.html#small-area-estimation-sae",
    "href": "slides/02-intro-bayes.html#small-area-estimation-sae",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Small Area Estimation (SAE)",
    "text": "Small Area Estimation (SAE)\n\nThe previous example is an example of an SAE problem.\n\n\n\nSmall area estimation is any of several statistical techniques involving the estimation of parameters for small sub-populations, generally used when the sub-population of interest is included in a larger survey1.\n\n\n\nThere is a hierarchical structure in SAE problems:\n\n\n\\[\n\\text{基隆} \\subset \\text{台灣} \\subset \\text{東亞} \\subset \\text{亞洲} \\subset{世界}\n\\]\n\n\nOne of the common frequentist models for SAE problems is the random effect model.\n\nWiki"
  },
  {
    "objectID": "slides/02-intro-bayes.html#small-area-estimation",
    "href": "slides/02-intro-bayes.html#small-area-estimation",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Small Area Estimation",
    "text": "Small Area Estimation\n\nBayesians typically use a hierarchical model to handle an SAE problem.\nIn this example, (conceptually) \\[\\begin{align*}\n  X \\mid p & \\sim \\bin\\left(n, p\\right)\\\\\n  p \\mid p_{\\text{TW}} & \\sim \\pi_1\\\\\n  p_{\\text{TW}} \\mid p_{\\text{World}} & \\sim \\pi_2\n\\end{align*}\\]\nNotations:\n\n\\(R = \\frac{p}{1-p}\\) is the Keelung’s gender ratio (parameter);\n\\(R_{\\text{TW}} = \\frac{p_{\\text{TW}}}{1-p_{\\text{TW}}}\\) is the Taiwan’s gender ratio (parameter);\n\\(p_{\\text{World}} = 0.5122\\)\n\nThis model is more complicated than the previous one, but descibes the data more accurately."
  },
  {
    "objectID": "slides/02-intro-bayes.html#what-is-good-and-bad-about-bayesian",
    "href": "slides/02-intro-bayes.html#what-is-good-and-bad-about-bayesian",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "What is good and bad about Bayesian?",
    "text": "What is good and bad about Bayesian?\n\nGood:\n\nconsistent and coherent: everything (sample or parameter) is a random variable\neverything is conditional: we only care about conditional independence rather than marginal independence\nstopping rule does not matter\n\nBad:\n\nthe choice of prior is subjective\ncomputationally challenging"
  },
  {
    "objectID": "slides/02-intro-bayes.html#exchangeability",
    "href": "slides/02-intro-bayes.html#exchangeability",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Exchangeability",
    "text": "Exchangeability\n\nDefinition 2 Let \\(p\\left(x_1, \\ldots, x_n\\right)\\) be the joint density of \\(X_1\\), \\(\\ldots, X_n\\). If \\(p\\left(x_1, \\ldots, x_n\\right)=p\\left(x_{\\pi(1)}, \\ldots, x_{\\pi(n)}\\right)\\) for all permutations \\(\\pi\\) of \\(\\{1, \\ldots, n\\}\\), then \\(X_1, \\ldots, X_n\\) are exchangeable.\n\n\nRoughly speaking, \\(X_1, \\ldots, X_n\\) are exchangeable if the subscript labels convey no information about the outcomes.\nApparently, independence implies exchangeability, but the converse is false.\nWhat is the relationship between conditional independence and exchangeability?"
  },
  {
    "objectID": "slides/02-intro-bayes.html#conditional-independence-and-exchangeability",
    "href": "slides/02-intro-bayes.html#conditional-independence-and-exchangeability",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Conditional independence and exchangeability",
    "text": "Conditional independence and exchangeability\n\nProposition 1 If \\(\\theta \\sim p(\\theta)\\) and \\(X_1, \\ldots, X_n\\) are conditionally i.i.d. given \\(\\theta\\), then marginally (unconditionally on \\(\\theta\\) ) \\(, X_1, \\ldots, X_n\\) are exchangeable.\n\n\nProof. Suppose \\(X_1, \\ldots, X_n\\) are conditionally iid given some unknown parameter \\(\\theta\\). Then for any permutation \\(\\pi\\) of \\(\\{1, \\ldots, n\\}\\) and any set of values \\(\\left(x_1, \\ldots, x_n\\right) \\in\\) \\(\\mc{X}^n\\) \\[\\begin{align*}\np\\left(x_1, \\ldots, x_n\\right) & =\\int p\\left(x_1, \\ldots, x_n \\mid \\theta\\right) p(\\theta) d \\theta & & \\text { (definition of marginal probability) } \\\\\n& =\\int\\left\\{\\prod_{i=1}^n p\\left(x_i \\mid \\theta\\right)\\right\\} p(\\theta) d \\theta & & \\text { ($X$'s are conditionally i.i.d.) } \\\\\n& =\\int\\left\\{\\prod_{i=1}^n p\\left(x_{\\pi(i)} \\mid \\theta\\right)\\right\\} p(\\theta) d \\theta & & \\text { (product does not depend on order) } \\\\\n& =p\\left(x_{\\pi(1)}, \\ldots x_{\\pi(n)}\\right) & & \\text { (definition of marginal probability) } .\n\\end{align*}\\]\n\n\n\nCh. 2.7 & 2.8 in Hoff’s book."
  },
  {
    "objectID": "slides/02-intro-bayes.html#de-finettis-theorem",
    "href": "slides/02-intro-bayes.html#de-finettis-theorem",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "de Finetti’s Theorem",
    "text": "de Finetti’s Theorem\n\nWe have seen that\n\n\n\\[\\begin{align*}\n\\left.\\begin{array}{l}\nX_1, \\ldots, X_n \\mid \\theta \\text { i.i.d } \\\\\n\\theta \\sim p(\\theta)\n\\end{array}\\right\\} \\Rightarrow X_1, \\ldots, X_n \\text { are exchangeable. }\n\\end{align*}\\]\n\n\nWhat about an arrow in the other direction?\n\n\nTheorem 1 (de Finetti) Let \\(X_i \\in \\mc{X}\\) for all \\(i \\in\\{1,2, \\ldots\\}\\). Suppose that, for any \\(n\\), \\(X_1, \\ldots, X_n\\) are exchangeable. Then our model can be written as \\[\\begin{align*}\np\\left(x_1, \\ldots, x_n\\right)=\\int\\left\\{\\prod_{i=1}^n p\\left(x_i \\mid \\theta\\right)\\right\\} p(\\theta) d \\theta\n\\end{align*}\\] for some parameter \\(\\theta\\), some prior distribution on \\(\\theta\\), and some sampling model \\(p(x \\mid \\theta)\\). The prior and sampling model depend on \\(p\\left(x_1, \\ldots, x_n\\right)\\)."
  },
  {
    "objectID": "slides/02-intro-bayes.html#de-finettis-theorem-1",
    "href": "slides/02-intro-bayes.html#de-finettis-theorem-1",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "de Finetti’s Theorem",
    "text": "de Finetti’s Theorem\n\n\nThe conclusion is\n\n\\[\\begin{align*}\n\\left.\\begin{array}{l}\nX_1, \\ldots, X_n \\mid \\theta \\text { are i.i.d. } \\\\\n\\theta \\sim p(\\theta)\n\\end{array}\\right\\} \\Leftrightarrow X_1, \\ldots, X_n \\text { are exchangeable for all } n \\text {. }\n\\end{align*}\\]\n\n\nThis justifies the use of prior distributions when samples are exchangeable.\nWhen is the condition “\\(X_1, \\ldots, X_n\\) are exchangeable for all \\(n\\)” reasonable?\n\n\\(X_1, \\ldots, X_n\\) are outcomes of a repeatable experiment;\n\\(X_1, \\ldots, X_n\\) are sampled from a finite population with replacement;\n\\(X_1, \\ldots, X_n\\) are sampled from an infinite population without replacement."
  },
  {
    "objectID": "slides/02-intro-bayes.html#stopping-rule",
    "href": "slides/02-intro-bayes.html#stopping-rule",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Stopping Rule",
    "text": "Stopping Rule\nLet \\(\\theta\\) be the probability of a particular coin landing on heads, and suppose we want to test the hypotheses \\[\\begin{align*}\nH_0: \\theta=1 / 2, \\quad H_1: \\theta&gt;1 / 2\n\\end{align*}\\] at a significance level of \\(\\alpha=0.05\\). Suppose we observe the following sequence of flips: \\[\n\\text{heads, heads, heads, heads, heads, tails (5 heads, 1 tails)}\n\\]\n\nTo perform a frequentist hypothesis test, we must define a random variable to describe the data.\nThe proper way to do this depends on exactly which of the following two experiments was actually performed:\n\n\n\nExample 1.1 in Essential Bayes"
  },
  {
    "objectID": "slides/02-intro-bayes.html#stopping-rule-1",
    "href": "slides/02-intro-bayes.html#stopping-rule-1",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Stopping Rule",
    "text": "Stopping Rule\nSuppose the experiment is “Flip six times and record the results.”\n\n\\(X\\) counts the number of heads, and \\(X \\sim \\bin(6, \\theta)\\).\nThe observed data was \\(x=5\\), and the \\(p\\)-value of our hypothesis test is \\[\\begin{align*}\np\\text{-value} & =\\P_{\\theta=1 / 2}(X \\geq 5) \\\\\n& =\\P_{\\theta=1 / 2}(X=5)+\\P_{\\theta=1 / 2}(X=6) \\\\\n& =\\frac{6}{64}+\\frac{1}{64}=\\frac{7}{64}=0.109375&gt;0.05 .\n\\end{align*}\\] So we fail to reject \\(H_0\\) at \\(\\alpha=0.05\\)."
  },
  {
    "objectID": "slides/02-intro-bayes.html#stopping-rule-2",
    "href": "slides/02-intro-bayes.html#stopping-rule-2",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Stopping Rule",
    "text": "Stopping Rule\nSuppose now the experiment is “Flip until we get tails.”\n\n\\(X\\) counts the number of the flip on which the first tails occurs, and \\(X \\sim \\text{Geometric}(1-\\theta)\\).\nThe observed data was \\(x=6\\), and the p-value of our hypothesis test is \\[\\begin{align*}\np \\text{-value} & = \\P_{\\theta=1 / 2}(X \\geq 6) \\\\\n& =1-\\P_{\\theta=1 / 2}(X&lt;6) \\\\\n& =1-\\sum_{x=1}^5 \\P_{\\theta=1 / 2}(X=x) \\\\\n& =1-\\left(\\frac{1}{2}+\\frac{1}{4}+\\frac{1}{8}+\\frac{1}{16}+\\frac{1}{32}\\right)=\\frac{1}{32}=0.03125&lt;0.05\n\\end{align*}\\] So we reject \\(H_0\\) at \\(\\alpha=0.05\\)."
  },
  {
    "objectID": "slides/02-intro-bayes.html#stopping-rule-3",
    "href": "slides/02-intro-bayes.html#stopping-rule-3",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "Stopping Rule",
    "text": "Stopping Rule\n\nThe result our hypothesis test depends on whether we would have stopped flipping if we had gotten a tails sooner.\nThe tests are dependent on what we call the stopping rule.\nThe likelihood for the actual value of \\(x\\) that was observed is the same for both experiments (up to a constant): \\[\\begin{align*}\np(x \\mid \\theta) \\propto \\theta^5(1-\\theta) .\n\\end{align*}\\]\nA Bayesian approach would take the data into account only through this likelihood.\nHomework: Show that under a Beta prior, the posteriors under the two stopping rules are the same."
  },
  {
    "objectID": "slides/02-intro-bayes.html#more-importantly",
    "href": "slides/02-intro-bayes.html#more-importantly",
    "title": "Lecture 02: Introduction to Bayesian Statistics",
    "section": "More importantly …",
    "text": "More importantly …\n\n\n\n\n\n\n\n\nHome\n\n\nImage source: https://twitter.com/LSpakeAnthro/status/1257766583629275137"
  },
  {
    "objectID": "slides/03-prior.html#introduction",
    "href": "slides/03-prior.html#introduction",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Introduction",
    "text": "Introduction\n\n\\[\n\\newcommand{\\mc}[1]{\\mathcal{#1}}\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\E}{\\mathbb{E}}\n\\renewcommand{\\P}{\\mathbb{P}}\n\\newcommand{\\var}{{\\rm Var}} % Variance\n\\newcommand{\\mse}{{\\rm MSE}} % MSE\n\\newcommand{\\bias}{{\\rm Bias}} % MSE\n\\newcommand{\\cov}{{\\rm Cov}} % Covariance\n\\newcommand{\\iid}{\\stackrel{\\rm iid}{\\sim}}\n\\newcommand{\\ind}{\\stackrel{\\rm ind}{\\sim}}\n\\renewcommand{\\choose}[2]{\\binom{#1}{#2}}  % Choose\n\\newcommand{\\chooses}[2]{{}_{#1}C_{#2}}  % Small choose\n\\newcommand{\\cd}{\\stackrel{d}{\\rightarrow}}\n\\newcommand{\\cas}{\\stackrel{a.s.}{\\rightarrow}}\n\\newcommand{\\cp}{\\stackrel{p}{\\rightarrow}}\n\\newcommand{\\bin}{{\\rm Bin}}\n\\newcommand{\\ber}{{\\rm Ber}}\n\\DeclareMathOperator*{\\argmax}{argmax}\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\]\n\n\nThe choice of prior distribution is the most critical and difficult step in Bayesian analysis.\nIn practice, the available prior information is often not precise enough to lead to an exact determination of the prior distribution.\nWe need to find a prior distribution that is compatible with the prior information.\nAnother problem is the determination of prior when the prior information is too vague or does not even exist."
  },
  {
    "objectID": "slides/03-prior.html#maximum-entropy-priors",
    "href": "slides/03-prior.html#maximum-entropy-priors",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Maximum Entropy Priors",
    "text": "Maximum Entropy Priors\n\nIf some characteristics of the prior distribution are known, assuming that they can be written as prior expectations, \\[\n\\E_{\\pi}\\left[g_k(\\theta)\\right]=\\omega_k, \\quad k = 1, \\ldots, K,\n\\] a way to select a prior \\(\\pi\\) satisfying these constraints is the maximum entropy method.\nLet \\(\\pi\\) be a discrete distribution. The Shannon Entropy1 of \\(\\pi\\) is \\[\n\\mc{E}(\\pi) =  -\\E_{\\pi}[\\log \\pi(\\theta)].\n\\]\n\nIntroduced by Shannon (1948)."
  },
  {
    "objectID": "slides/03-prior.html#intuition-behind-shannon-entropy",
    "href": "slides/03-prior.html#intuition-behind-shannon-entropy",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Intuition behind Shannon Entropy",
    "text": "Intuition behind Shannon Entropy\n\nEntropy is a measure of randomness: high entropy = high randomness\nEntropy is the expectation of information: \\(\\mc{E}(\\pi) = \\E_{\\pi}(I(X))\\), where \\(I(x)\\) is the information of the event \\(\\{X = x\\}\\).\nRoughly speaking, information of an event \\(E\\) is the knowledge you obtained after the occurrence of \\(E\\) ."
  },
  {
    "objectID": "slides/03-prior.html#shannons-axioms-for-information",
    "href": "slides/03-prior.html#shannons-axioms-for-information",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Shannon’s Axioms for Information",
    "text": "Shannon’s Axioms for Information\n\nAn event that always happens yields no information.\nThe less probable an event is, the more information it yields.\nIf two independent events are measured separately, the total amount of information is the sum of the information of the individual events.\n\n\nThat is, the information \\(I(A)\\) of an event \\(A\\) satisfies\n\n\n\\(I(A) = 0\\) if \\(\\P(A) = 1\\).\n\\(I(A)\\) is a decreasing function of \\(\\P(A)\\).\n\\(I(A\\cap B) = I(A) + I(B)\\) if \\(A\\) and \\(B\\) are independent.\n\n\n Shannon’s solution: \\(I(A) = -\\log \\P(A)\\) for \\(\\P(A) &gt; 0\\)"
  },
  {
    "objectID": "slides/03-prior.html#shannon-entropy",
    "href": "slides/03-prior.html#shannon-entropy",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Shannon Entropy",
    "text": "Shannon Entropy\n\nLet \\(X\\) be a discrete random variable with probability mass function \\(\\pi(x)\\). The Shannon information of \\(\\pi\\) is \\[\nI(x) \\coloneqq I(\\{X = x\\}) = -\\log \\P(X = x) = -\\log \\pi(x).\n\\]\nThe Shannon entropy of \\(\\pi\\) is \\(\\mc{E}(\\pi) = \\E_{\\pi}(I(X)) = -\\E_{\\pi}(\\log \\pi(X))\\).\nIf the support of \\(\\pi(x)\\) is a finite set, say \\(\\{x_1,\\ldots, x_m\\}\\), then \\(\\mc{E}(\\pi) \\leq \\log m\\) and the equality holds when \\(\\pi(x) = \\frac{1}{m}\\).\nWhat if \\(X\\) is continuous? If \\(\\pi(x)\\) is a probability density, the information \\(-\\log \\pi(x)\\) can be negative."
  },
  {
    "objectID": "slides/03-prior.html#relative-entropy",
    "href": "slides/03-prior.html#relative-entropy",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Relative Entropy",
    "text": "Relative Entropy\n\nIt does not make sense to have a negative information.\nBut ``relative information” can be negative.\nLet \\(\\pi_0\\) be a reference distribution. The relative information of \\(\\pi\\) with respect to \\(\\pi_0\\) is \\[\nI(x; \\pi_0) \\coloneqq \\log \\frac{1}{\\pi_0(x)} - \\log \\frac{1}{\\pi(x)} = \\log \\frac{\\pi(x)}{\\pi_0(x)}\n\\]\nThen by Jensen’s inequality \\[\n\\E_{\\pi_0}[I(X;\\pi_0)] = \\mc{E}(\\pi_0) - \\mc{E}(\\pi, \\pi_0) \\leq 0\n\\] and the equality holds when \\(\\pi = \\pi_0\\)."
  },
  {
    "objectID": "slides/03-prior.html#relative-entropy-1",
    "href": "slides/03-prior.html#relative-entropy-1",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Relative Entropy",
    "text": "Relative Entropy\n\nCross entropy: \\(\\mc{E}(\\pi, \\pi_0) = - \\E_{\\pi_0}(\\log \\pi(X))\\)\nRelative entropy: \\[\n\\mc{E}(\\pi_0\\| \\pi) = - \\E_{\\pi_0}[I(X;\\pi_0)] = \\E_{\\pi_0}\\left[\\log \\frac{\\pi_0(x)}{\\pi(x)}\\right] = D_{KL}(\\pi_0\\| \\pi) \\geq 0\n\\]\nIt is also called the Kullback-Liebler divergence.\nA common choice of the reference distribution \\(\\pi_0\\) is non-informative distributions, e.g., the Lebesgue measure."
  },
  {
    "objectID": "slides/03-prior.html#entropyinformation",
    "href": "slides/03-prior.html#entropyinformation",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Entropy/Information",
    "text": "Entropy/Information\nSome take-home messages:\n\nEntropy \\(\\approx\\) Information \\(\\approx\\) Uncertainty \\(\\approx\\) Energy \\(\\approx\\) Temparature\nThere are different definitions of entropy, e.g. Rényi entropy, and therefore different divergences can be induced.\nEntropy plays the role of utility functions in decision theory: an inference procedure is obtained by maximizing the entropy."
  },
  {
    "objectID": "slides/03-prior.html#maximum-entropy-prior-mep",
    "href": "slides/03-prior.html#maximum-entropy-prior-mep",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Maximum Entropy Prior (MEP)",
    "text": "Maximum Entropy Prior (MEP)\n\nThe maximum entropy prior (MEP) (with respect to a reference distribution \\(\\pi_0\\)) is the solution to the optimization problem \\[\\begin{equation}\\label{eq:MEP}\n\\begin{split}\n\\max_{\\pi \\in \\Gamma} & \\; \\mc{E}(\\pi; \\pi_0)\\\\\n& s.t. \\quad \\E_{\\pi}\\left[g_k(\\theta)\\right]=\\omega_k, \\quad k = 1, \\ldots, K\n\\end{split}\n\\end{equation}\\] where \\(\\Gamma\\) is a class of candidate priors.\nThe existence of the solution depends on \\(g_k\\)’s, \\(\\Gamma\\), and \\(\\pi_0\\).\nThe prior \\(\\pi\\) maximizing the entropy is, in this information-theoretic sense, minimizing the prior information brought through \\(\\pi\\) about \\(\\theta\\)."
  },
  {
    "objectID": "slides/03-prior.html#discrete-mep",
    "href": "slides/03-prior.html#discrete-mep",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Discrete MEP",
    "text": "Discrete MEP\n\nLet \\(\\Theta=\\{\\theta_1, \\ldots, \\theta_m\\}\\) and \\(\\pi_0(\\theta_i) = \\frac{1}{m}\\) be the reference distribution.\nThe prior informations are \\[\n\\E_{\\pi}\\left[g_k(\\theta)\\right]=\\omega_k, \\quad k = 1, \\ldots, K.\n\\]\nThe MEP for \\(\\theta\\) is \\[\n\\pi^*(\\theta_i)=\\frac{\\exp \\left\\{\\sum_{k=1}^K \\lambda_k g_k\\left(\\theta_i\\right)\\right\\}}{\\sum_j \\exp \\left\\{\\sum_{k=1}^K \\lambda_k g_k\\left(\\theta_j\\right)\\right\\}}\n\\] where the \\(\\lambda_k\\)’s are obtained from \\(\\eqref{eq:MEP}\\) as Lagrange multipliers.\nHere \\(\\Gamma\\) is the class of all discrete distributions on \\(\\Theta\\), i.e., \\(\\Gamma = \\{(p_1, \\ldots, p_m): \\sum p_i = 1\\}\\).\nThe proof is a simple application of Lagrange multipliers."
  },
  {
    "objectID": "slides/03-prior.html#continuous-mep",
    "href": "slides/03-prior.html#continuous-mep",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Continuous MEP",
    "text": "Continuous MEP\n\nLet \\(\\Theta = \\R\\) and the prior information be \\[\n\\E_{\\pi}\\left[g_k(\\theta)\\right]=\\omega_k, \\quad k = 1, \\ldots, K.\n\\]\nThe MEP for \\(\\theta\\) is \\[\n\\pi^*(\\theta)=\\frac{\\exp \\left\\{\\sum_{k=1}^K \\lambda_k g_k(\\theta)\\right\\} \\pi_0(\\theta)}{\\int \\exp \\left\\{\\sum_{k=1}^K \\lambda_k g_k(\\eta)\\right\\} \\pi_0(d \\eta)}.\n\\]\n??"
  },
  {
    "objectID": "slides/03-prior.html#examples",
    "href": "slides/03-prior.html#examples",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Examples",
    "text": "Examples\n\nWithout any prior information, the MEP is the uniform distribution.\nWith \\(\\E_{\\pi}(\\theta) = \\mu\\), the MEP is \\(\\pi^*(\\theta) \\propto e^{\\lambda\\theta}\\), which can not be normalized to 1.\nWith \\(\\E_{\\pi}(\\theta) = \\mu\\) and \\(\\var_{\\pi}(\\theta) = \\sigma^2\\), the MEP is \\(N(\\mu, \\sigma^2)\\)."
  },
  {
    "objectID": "slides/03-prior.html#problems-with-mep",
    "href": "slides/03-prior.html#problems-with-mep",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Problems with MEP",
    "text": "Problems with MEP"
  },
  {
    "objectID": "slides/03-prior.html#parametric-approximations",
    "href": "slides/03-prior.html#parametric-approximations",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Parametric Approximations",
    "text": "Parametric Approximations\n\nA more practical solution to incorporate the prior information is to use parametric approximations.\nChoose a parametric family, e.g. normal, and find one in the family that matches the prior information (exactly or approximately).\nExample: Suppose the prior informations are: median = 0, lower quartile = -1, and upper quartile = 1.\nThe normal distribution satisfying these constraints is \\(N(0, 2.19)\\).\nThe Cauchy distribution satisfying these constraints is \\(\\text{Cauchy}(0,1)\\).\nBoth are reasonbale prior distributions (depending on the likelihood and data)."
  },
  {
    "objectID": "slides/03-prior.html#conjugate-prior",
    "href": "slides/03-prior.html#conjugate-prior",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Conjugate prior",
    "text": "Conjugate prior\n\nDefinition 1 A class \\(\\mc{P}\\) of prior distributions for \\(\\theta\\) is called conjugate for a sampling model \\(p(x \\mid \\theta)\\) if \\[\\begin{align*}\n\\pi(\\theta) \\in \\mc{P} \\Rightarrow \\pi(\\theta \\mid x) \\in \\mc{P} .\n\\end{align*}\\]\n\n\nUsually, the class \\(\\mc{P}\\) is a parametric family with a finite number of parameters.\nExample: Beta is conjugate for the binomial model.\nConjugate priors make posterior calculations easy, but might not actually represent our prior information.\nHowever, mixtures of conjugate prior distributions are very flexible and are computationally tractable."
  },
  {
    "objectID": "slides/03-prior.html#exponential-families",
    "href": "slides/03-prior.html#exponential-families",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Exponential families",
    "text": "Exponential families\n\nRecall that a family of distributions is an exponential family if its pdf/pmf can be written as \\[\\begin{align*}\nf(x;\\theta) & = h(x)\\exp\\left(\\sum_{i=1}^k w_i(\\theta)T_i(x) - \\psi(\\theta)\\right)\\\\\n& = h(x)\\exp\\left(\\sum_{i=1}^k \\eta_iT_i(x)-\\tilde{\\psi}(\\eta)\\right), \\quad \\eta_i = w_i(\\theta), \\eta = [\\eta_1, \\ldots, \\eta_k].\n\\end{align*}\\]\n\n\\(\\eta\\) is the natural parameter.\n\\(T(X) = [T_1(X), \\ldots, T_k(X)]\\) is a sufficient statistic; it is complete if the parameter space is an open set in \\(\\R^k\\).\n\nExample: Normal, Gamma, Beta, Binomial (with known \\(n\\)), Poisson, …\nNot an exponential family: \\(\\text{Unif}(\\theta, \\theta+1)\\) (if the support of the distribution depends on the parameter, then it is not an exponential family)."
  },
  {
    "objectID": "slides/03-prior.html#constructing-a-conjugate-prior",
    "href": "slides/03-prior.html#constructing-a-conjugate-prior",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Constructing a conjugate prior",
    "text": "Constructing a conjugate prior\n\nSuppose \\(f(x\\mid \\theta) = h(x)\\exp(\\theta^Tx - \\psi(\\theta))\\) (natural parametrization).\nHow to construct a conjugate prior for \\(f(x \\mid \\theta)\\)?\nWe need \\(\\pi(\\theta)\\) and \\(\\pi(\\theta \\mid x)\\) to be in the same family.\n\n\n\\[\n\\begin{align}\n  \\pi(\\theta \\mid x) = \\frac{f(x \\mid \\theta)\\pi(\\theta)}{\\int f(x\\mid \\theta^{\\prime})\\pi(\\theta^{\\prime})d\\theta^{\\prime}}\n  & = \\frac{{\\color{green}\\pi(\\theta)}{\\color{magenta}h(x)}\\exp(\\theta^Tx {\\color{green} - \\psi(\\theta)})}{{\\color{magenta}m(x)}}\\\\\n    &\\class{fragment}{{} = \\exp\\left[x^T\\theta - \\left(\\psi(\\theta)\\right)\\right]}         \\\\[3px]\n\\end{align}\n\\]"
  },
  {
    "objectID": "slides/03-prior.html#pros-and-cons",
    "href": "slides/03-prior.html#pros-and-cons",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Pros and cons",
    "text": "Pros and cons"
  },
  {
    "objectID": "slides/03-prior.html#some-practical-guides-for-choosing-priors",
    "href": "slides/03-prior.html#some-practical-guides-for-choosing-priors",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Some practical guides for choosing priors",
    "text": "Some practical guides for choosing priors\n\nWith prior information:\n\nFind the MEP\nFind a (conjugate) parametric prior that approximates the prior information\n\nWithout prior information:\n\nUse conjugate priors (if applicable) and hyper-priors\nUse noninformative priors, e.g., Jeffreys prior, reference priors, vague priors\n\nFinally, perform some sensitivity analysis to access priors’ influence on the result.\n\n\n\nHome"
  },
  {
    "objectID": "slides/03-prior.html#introduction-1",
    "href": "slides/03-prior.html#introduction-1",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Introduction",
    "text": "Introduction\nThe goal of lecture is to:\n\nfind a distribution compatible with prior information"
  },
  {
    "objectID": "slides/03-prior.html#prior-information",
    "href": "slides/03-prior.html#prior-information",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Prior Information",
    "text": "Prior Information\n\nSuppose the prior information for \\(\\theta\\) is given through some expectations. \\[\n\\E_{\\pi}\\left[g_k(\\theta)\\right]=\\omega_k, \\quad k = 1, \\ldots, K,\n\\]\nFor example, the census records show that the sex ratio at birth is around 1.05 (ranging from 1.03 to 1.07 for most countries).\nThe prior information about the sex ratio \\(\\theta\\) can be expressed as \\[\n    \\E_{\\pi}(\\theta) = 1.05 \\quad \\text{and} \\quad \\var_{\\pi}(\\theta) = 0.1^2.\n\\]\nObviously, there are many distributions compatible with these constraints.\nWe will discuss two approaches for choosing prior distributions compatible with these information."
  },
  {
    "objectID": "slides/03-prior.html#entropy",
    "href": "slides/03-prior.html#entropy",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Entropy",
    "text": "Entropy\n\nLet \\(\\pi\\) be a discrete distribution. The Shannon Entropy1 of \\(\\pi\\) is \\[\n\\mc{E}(\\pi) =  -\\E_{\\pi}[\\log \\pi(\\theta)].\n\\]\n\nIntroduced by Shannon (1948)."
  },
  {
    "objectID": "slides/03-prior.html#conjugate-prior-1",
    "href": "slides/03-prior.html#conjugate-prior-1",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Conjugate prior",
    "text": "Conjugate prior\n\nDefinition 1 A class \\(\\mc{P}\\) of prior distributions for \\(\\theta\\) is called conjugate for a sampling model \\(p(x \\mid \\theta)\\) if \\[\\begin{align*}\n\\pi(\\theta) \\in \\mc{P} \\Rightarrow \\pi(\\theta \\mid x) \\in \\mc{P} .\n\\end{align*}\\]\n\n\nUsually, the class \\(\\mc{P}\\) is a parametric family with a finite number of parameters.\nExample: Beta is conjugate for the binomial model.\nConjugate priors make posterior calculations easy, but might not actually represent our prior information.\nHowever, mixtures of conjugate prior distributions are very flexible and are computationally tractable."
  },
  {
    "objectID": "slides/03-prior.html#jeffreys-prior",
    "href": "slides/03-prior.html#jeffreys-prior",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Jeffreys prior",
    "text": "Jeffreys prior\n\n\nRecall that the Fisher information of a pdf/pmf \\(f(x\\mid\\theta)\\) is given by\n\n\\[\nI(\\theta)=\\E_\\theta\\left[\\left(\\frac{\\partial \\log f(X \\mid \\theta)}{\\partial \\theta}\\right)^2\\right] \\stackrel{(*)}{=} -\\E_\\theta\\left[\\frac{\\partial^2 \\log f(X \\mid \\theta)}{\\partial \\theta^2}\\right].\n\\]\n\n\nThe Jeffreys prior distribution is \\(\\pi_J(\\theta) \\propto \\sqrt{I(\\theta)}\\), defined up to a normalization constant when \\(\\pi_J\\) is proper.\n\n\n\nThe equality \\((*)\\) holds under some regularity conditions on \\(f(x\\mid\\theta)\\)."
  },
  {
    "objectID": "slides/03-prior.html#reference-prior",
    "href": "slides/03-prior.html#reference-prior",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Reference prior",
    "text": "Reference prior\n\nBernardo (1979) proposed a modification of the Jeffreys approach called the reference prior approach.\nA major difference is that this method distinguishes between parameters of interest and nuisance parameters.\nHence the prior depends on the sampling model as well as the inferential problem.\nThe main idea behind the reference approach is to a prior that maximizes the information brought by the data, i.e. the KL divergence between prior and posterior.\nIt can be shown that for one-parameter models, the reference approach gives the Jeffreys prior."
  },
  {
    "objectID": "slides/03-prior.html#matching-prior",
    "href": "slides/03-prior.html#matching-prior",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Matching prior",
    "text": "Matching prior"
  },
  {
    "objectID": "slides/03-prior.html#noninformative-prior-1",
    "href": "slides/03-prior.html#noninformative-prior-1",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Noninformative prior",
    "text": "Noninformative prior\n\nWhen there is no prior information or the prior information is unreliable, should we still use Bayesian techniques?\nThe answer is YES, due to some optimality criteria (we will discuss this in the next lecture).\nIn such cases, the priors should be derived from the sampling distribution, since that is the only information we have.\nThese priors are called noninformative priors, or objective/default priors.\nWe will introduce some principles for deriving noninformative priors."
  },
  {
    "objectID": "slides/03-prior.html#laplaces-prior",
    "href": "slides/03-prior.html#laplaces-prior",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Laplace’s prior",
    "text": "Laplace’s prior\n\nFor the binomial model, Laplace proposed to use the uniform distribution for \\(p\\).\nIt is called the principle of insufficient reason:\n\n\n\nIf we are ignorant of the ways an event can occur, the event will occur equally likely in any way. 1\n\n\n\nIt is also called the equiprobability principle.\n\nhttps://mathworld.wolfram.com/PrincipleofInsufficientReason.html"
  },
  {
    "objectID": "slides/03-prior.html#criticisms-against-laplaces-prior",
    "href": "slides/03-prior.html#criticisms-against-laplaces-prior",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Criticisms against Laplace’s prior",
    "text": "Criticisms against Laplace’s prior\n\nWhen the parameter space is not compact, this principle leads to an improper prior.\n\nA distribution \\(\\pi\\) is improper if \\(\\pi(\\theta) \\geq 0\\) but \\(\\int \\pi(\\theta)d\\theta = \\infty\\).\nHowever, it is actually possible to work with improper priors, as long as we do not try to interpret them as probability distributions.\n\nLaplace’s prior is not invariant under reparametrization.\n\nSuupose we assign a unifrom prior for \\(\\theta\\): \\(\\pi(\\theta) \\propto 1\\).\nWe consider a reparametrization \\(\\eta = g(\\theta)\\), where \\(g\\) is one-to-one.\nThe corresponding prior is \\[\n\\pi^*(\\eta)=\\left|\\frac{d}{d \\eta} g^{-1}(\\eta)\\right|\n\\] which is not constant."
  },
  {
    "objectID": "slides/03-prior.html#example",
    "href": "slides/03-prior.html#example",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Example",
    "text": "Example\n\nSuppose \\(\\Theta = [0, 1]\\) and \\(\\pi(\\theta) = 1\\) for \\(\\theta \\in \\Theta\\).\nConsider the odds \\(\\eta = \\frac{\\theta}{1-\\theta}\\), which is one-to-one on \\(\\Theta\\).\nThen \\(\\pi^*(\\eta) = \\left|\\frac{d}{d \\eta} g^{-1}(\\eta)\\right| = \\frac{1}{(1+\\eta)^2}\\), that is, the prior prefers small \\(\\eta\\) (corresponding to small \\(\\theta\\))."
  },
  {
    "objectID": "slides/03-prior.html#jeffreys-prior-1",
    "href": "slides/03-prior.html#jeffreys-prior-1",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Jeffreys prior",
    "text": "Jeffreys prior\nJeffreys prior has several advantages:\n\nIt depends only on the sampling model, through the Fisher information.\nThe Fisher information is an indicator of the amount of information brought by the model (or the observation) about \\(\\theta\\).\nIt is invariant under reparametrization."
  },
  {
    "objectID": "slides/03-prior.html#example-1",
    "href": "slides/03-prior.html#example-1",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Example",
    "text": "Example\nIf \\(X \\sim \\bin(n, p)\\),\n\n\\[\n\\begin{aligned}\nf(x \\mid p) & =\\left(\\begin{array}{c}\nn \\\\\nx\n\\end{array}\\right) p^x(1-p)^{n-x}, \\\\\n\\frac{\\partial^2 \\log f(x \\mid p)}{\\partial p^2} & = - \\frac{x}{p^2} - \\frac{n-x}{(1-p)^2}, \\\\\nI(p) & =n\\left[\\frac{1}{p}+\\frac{1}{1-p}\\right]=\\frac{n}{p(1-p)} .\n\\end{aligned}\n\\]\n\n\nTherefore, the Jeffreys prior for this model is \\[\n\\pi_J(p) \\propto[p(1-p)]^{-1 / 2}\n\\] and is thus proper, since it is a \\(\\text{Beta}(1/2, 1/2)\\) distribution."
  },
  {
    "objectID": "slides/03-prior.html#multidimensional-parameters",
    "href": "slides/03-prior.html#multidimensional-parameters",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Multidimensional parameters",
    "text": "Multidimensional parameters\n\nFor \\(\\theta \\in \\R^k\\), the Fisher information matrix \\(I(\\theta)\\) has the following elements,\n\n\n\\[\nI_{i j}(\\theta)=-\\mathbb{E}_\\theta\\left[\\frac{\\partial^2}{\\partial \\theta_i \\partial \\theta_j} \\log f(x \\mid \\theta)\\right] \\quad(i, j=1, \\ldots, k).\n\\]\n\n\nThe Jeffreys noninformative prior is then defined by \\(\\pi_J(\\theta) \\propto \\sqrt{\\det(I(\\theta))}\\).\nIf \\(f(x \\mid \\theta)\\) belongs to an exponential family, \\(f(x \\mid \\theta)=h(x) \\exp (\\theta \\cdot x-\\psi(\\theta))\\), the Fisher information matrix is given by \\(I(\\theta)=\\nabla \\nabla^t \\psi(\\theta)\\) and \\[\n\\pi_J(\\theta) \\propto\\left(\\prod_{i=1}^k \\psi_{i i}^{\\prime \\prime}(\\theta)\\right)^{1 / 2}\n\\] where \\(\\psi_{i i}^{\\prime \\prime}(\\theta)=\\frac{\\partial^2}{\\partial \\theta_i^2} \\psi(\\theta)\\)."
  },
  {
    "objectID": "slides/03-prior.html#limitations-of-jeffreys-prior",
    "href": "slides/03-prior.html#limitations-of-jeffreys-prior",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Limitations of Jeffreys prior",
    "text": "Limitations of Jeffreys prior\n\nJeffreys prior works well for one-parameter models.\nFor multiparameter models however, Jeffreys prior leads to incoherences or even paradoxes.\nThey do not necessarily perform satisfactorily for all inferential purposes, in particular when considering subvectors of interest (see Example 3.5.9 in Bayesian Choice)."
  },
  {
    "objectID": "slides/03-prior.html#example-2",
    "href": "slides/03-prior.html#example-2",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Example",
    "text": "Example\n\nBeta(1,1) (blue) and Beta(1/2, 1/2) (red)"
  },
  {
    "objectID": "slides/03-prior.html#example-3",
    "href": "slides/03-prior.html#example-3",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Example",
    "text": "Example\n\nConsider \\(X \\sim N(\\mu, \\sigma^2)\\) with \\(\\theta = (\\mu, \\sigma^2)\\) unknown.\nIn this case, \\[\nI(\\theta)  =\\left(\\begin{array}{cc}\n1 / \\sigma^2 & 0 \\\\\n0 & 2 / \\sigma^2\n\\end{array}\\right).\n\\]\nThus \\(\\pi_J(\\mu, \\sigma^2) \\propto \\sigma^{-2}\\).\nIf we assume \\(\\mu\\) and \\(\\sigma^2\\) are a priori independent, then \\[\n\\pi_J(\\mu, \\sigma^2) = \\pi_J(\\mu)\\pi_J(\\sigma^2) \\propto \\sigma^{-1}.\n\\]\nTheoretically, \\(\\pi_J(\\mu,\\sigma^2) \\propto \\sigma^{-1}\\) has better convergence properties than \\(\\pi_J(\\mu,\\sigma^2) \\propto \\sigma^{-2}\\)."
  },
  {
    "objectID": "slides/03-prior.html#invariance-of-jeffreys-prior",
    "href": "slides/03-prior.html#invariance-of-jeffreys-prior",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Invariance of Jeffreys prior",
    "text": "Invariance of Jeffreys prior\n\nBy definition, \\(I(\\theta) = I(h(\\theta))[h^{\\prime}(\\theta)]^2\\) for any one-to-one \\(h\\).\nLet \\(\\eta = g(\\theta)\\) and \\(\\theta \\sim \\pi_J(\\theta) \\propto \\sqrt{I(\\theta)}\\).\nThen \\[\\begin{align*}\n\\pi^*(\\eta) & = \\pi_J(g^{-1}(\\eta))\\left|\\frac{d}{d \\eta} g^{-1}(\\eta)\\right|\n= \\sqrt{I(g^{-1}(\\eta))}\\left|\\frac{d}{d \\eta} g^{-1}(\\eta)\\right| \\\\\n& = \\sqrt{I(\\eta)[h^{\\prime}(\\eta)]^{-2}}|h^{\\prime}(\\eta)| \\quad \\text{(Let $h = g^{-1}$)}\\\\\n& = \\sqrt{I(\\eta)} = \\pi_J(\\eta).\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/03-prior.html#example-4",
    "href": "slides/03-prior.html#example-4",
    "title": "Lecture 03: From Prior Information to Prior Distribution",
    "section": "Example",
    "text": "Example"
  }
]