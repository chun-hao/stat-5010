---
title: "Lecture 08: Hamiltonian Monte Carlo and Variational Inference"
author: "Chun-Hao Yang"
footer: "[Home](https://chunhaoy.com/stat-5010/)"
format: 
    revealjs:
        theme: slides.scss
        chalkboard: true
        slide-number: true
        html-math-method: mathjax
        incremental: true
        scrollable: true
        include-in-header: 
            - text: 
                <link href='https://fonts.googleapis.com/css?family=Fira Code' rel='stylesheet'>
execute:
    echo: false
    warning: false
    cache: true
    freeze: true
---


## Motivation 

-   **In theory**, the Metropolis algorithm (with an arbitrary proposal) works for any distribution in any dimension.
-   **In practice**, the Metropolis algorithm is inefficient for high-dimensional distributions.
-   Current research in MCMC focuses on finding good proposals to speed-up the algorithm, together with theoretical guarantees, e.g., making sure that the chain converges to the target distribution.
-   In this lecture, we will introduce two popular MCMC algorithms: Hamiltonian Monte Carlo (HMC) and No-U-Turn Sampler (NUTS).
-   These two algorithms are the ones used in the `Stan` software.

## A few words about acceptance rate

Ideally, we want the acceptance rate to be [far from 0 and 1]{.underline}.

:::{.nonincremental}

-   If the acceptance rate is too low, the Markov chain is not moving.
-   If the acceptance rate is too high, the Markov chain is only exploring the high-density region.

:::

```{r}
#| fig-align: center
log_target <- function(x) {
    -x^2/2
}
set.seed(2023)
m <- 500
x1 <- rep(0, m); x2 <- rep(0, m)
sd1 <- 0.1; sd2 <- 10
accept1 <- 0; accept2 <- 0
for(i in 2:m){
    x1_new <- rnorm(1, x1[i-1], sd1)
    x2_new <- rnorm(1, x2[i-1], sd2)
    r1 <- exp(log_target(x1_new) - log_target(x1[i-1]))
    r2 <- exp(log_target(x2_new) - log_target(x2[i-1]))
    if(runif(1) < r1){
        x1[i] <- x1_new; accept1 <- accept1 + 1
    } else {
        x1[i] <- x1[i-1]
    }
    if(runif(1) < r2){
        x2[i] <- x2_new; accept2 <- accept2 + 1
    } else {
        x2[i] <- x2[i-1]
    }
}

par(mfrow=c(1,2))
plot(x1, 1:m, type="l", xlab="x", ylab="iteration", 
     main=paste("sd = 0.1; accept. rate=", round(accept1/m, 2)), 
     xlim = c(-3,3))
curve(dnorm(x)/0.4*m, col="red", add=TRUE, lwd = 2)

plot(x2, 1:m, type="l", xlab="x", ylab="iteration", 
     main=paste("sd = 10; accept. rate=", round(accept2/m, 2)), 
     xlim = c(-3,3))
curve(dnorm(x)/0.4*m, col="red", add=TRUE, lwd = 2)





```


## Adaptive MCMC

-   In the original Metropolis algorithm, the proposal distribution is fixed.
-   This can be inefficient, since after some exploration, we gain some knowledge about the target distribution, and we can use this knowledge to improve the proposal distribution.
-   This can be easily implemented, e.g., reducing the variance of Gaussian proposal every 100 iterations.
-   However, the theoretical analysis is complicated since the Markov chain is no longer time-homogeneous.
-   Can we assure that the adaptive Markov chain still converges to the target distribution?

::: aside

The material is adapted from <http://probability.ca/jeff/ftpdir/Cambridge2010.pdf>

:::

## Optimal Gaussian proposal

-   Let $\pi$ be a distribution supported on $\Theta \subseteq \mathbb{R}^d$.
-   We want to sample from $\pi$ using Metropolis algorithm with a Gaussian proposal $N_d(\theta^{(t-1)}, \Xi)$.
-   What is the optimal choice of $\Xi$?
-   What do we mean by optimal in MCMC? We want the fastest convergence of the Markov Chain.
-   Roberts & Rosenthal (2001)[^RR2001] showed that the optimal choice is
    $$
    \Xi = \frac{2.38^2}{d} \Sigma_{\pi},
    $$
    where $\Sigma_{\pi}$ is the covariance matrix of $\pi$.
-   But we don't know $\Sigma_{\pi}$! Estimate it!
    
    
[^RR2001]: Roberts, G. O., & Rosenthal, J. S. (2001). *Optimal Scaling for Various Metropolis-Hastings Algorithms.* Statistical Science, 16(4), 351â€“367.

## Adaptive Random Walk Metropolis
-   Algorithm:
    1. <span style="color:magenta;">At $t$th iteration, compute $\hat{\Sigma}_n$ using $\theta^{(1)}, \ldots, \theta^{(t-1)}$.</span>
    2. Sample $\theta^*$ from <span style="color:magenta;">$N_d\left(\theta^{(t-1)}, \frac{(2.38)^2}{d}\hat{\Sigma}_n\right)$</span>.
    3. Compute the acceptance ratio $\rho(\theta^{(t-1)}, \theta^{*})=\min\left\{\frac{\pi(\theta^* \mid x)}{\pi(\theta^{(t-1)} \mid x)}, 1\right\}$.
    4. Set
    $$
    \theta^{(t)}= \begin{cases}\theta^* & \text { with prob. } \rho(\theta^{(t-1)}, \theta^{*}) \\ \theta^{(t-1)} & \text { with prob. } 1-\rho(\theta^{(t-1)}, \theta^{*}).\end{cases}
    $$
-   The simplest choice of $\hat{\Sigma}_n$ is the sample covariance matrix.
-   However, it is not a good choice in high dimensions.
-   Google: ``High-dimensional covariance estimation''!

## Example

Consider $\pi(\theta) = \frac{1}{2}N(10,1) + \frac{1}{2}N(-10, 1)$.

```{r}

```

## Does it work?

## Metropolis-adjusted Langevin algorithm (MALA)

-   Proposal: $\theta^{(t)} \sim N_d\left(\theta^{(t-1)} + \frac{1}{2}\Sigma\nabla\log\pi(\theta^{(t-1)}), \Sigma\right)$

## Hamiltonian Monte Carlo (HMC)[^HMC]

[^HMC]: Neal, R. M. (2011). *MCMC using Hamiltonian dynamics.* Handbook of markov chain monte carlo, 2(11), 2.

## Hamiltonian dynamics

-   Let $p$ be a particle with position $x$ and velocity $v$.
-   The Hamiltonian of $p$ is the sum of its **kinetic energy** and **potential energy**:
    $$
    H(x, v) = U(x) + K(v).
    $$
-   $U(x)$ is the potential energy which is proportional to the height at $x$
-   $K(v)$ is the kinetic energy

## HMC

-   At $t$th iteration, we randomly assign a velocity $v^{(0)}$ for $\theta^{(t-1)}$.


## No-U-Turn Sampler (NUTS)[^NUTS]


[^NUTS]: Hoffman, M. D., & Gelman, A. (2014). *The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.* J. Mach. Learn. Res., 15(1), 1593-1623.


# Variational Inference