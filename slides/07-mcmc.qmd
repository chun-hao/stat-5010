---
title: "Lecture 07: Markov Chain Monte Carlo"
author: "Chun-Hao Yang"
footer: "[Home](https://chunhaoy.com/stat-5010/)"
format: 
    revealjs:
        theme: slides.scss
        chalkboard: true
        slide-number: true
        html-math-method: mathjax
        incremental: true
        scrollable: true
execute:
    echo: false
    warning: false
    cache: true
    freeze: auto
---

## Motivation 

-   We have seen that in many cases, the posterior is only available upto a normalizing constant.
-   To compute the posterior mean, we need to numerically (i) compute the normalizing constant and (ii) compute the posterior mean.
-   Numerical integration in high dimension is very difficult and we will resort to Monte Carlo methods, which use random numbers to compute/approximate the integral.
-   The idea is to generate a large number of (iid) random samples from the posterior distribution and use the sample mean as an approximation to the posterior mean.
-   There are a few questions:
    +   how to generate iid random samples from an arbitrary distribution?
    +   how to do it without knowing the normalizing constant?

## Markov Chain Monte Carlo (MCMC)

-   MCMC uses samples from a Markov chain whose stationary distribution is the target distribution.
-   Hence the samples are **not** independent and **not** from the target distribution.
-   They are only [iid from the target distribution]{.underline} asymptotically.
-   The problem is now how to construct a Markov chain whose stationary distribution is the posterior.
-   We will introduce three algorithms:
    +   Gibbs sampler
    +   Metropolis-Hastings algorithm
    +   Hamiltonian Monte Carlo (HMC)

# Gibbs Sampler

## Gibbs Sampler

# Metropolis-Hastings Algorithm

## Metropolis Algorithm

## Metropolis-Hastings Algorithm

# Diagnostic of MCMC

-   convergence
-   mixing
-   autocorrelation
-   effective sample size
-   burn-in
-   thinning
-   autocorrelation time


## Example

