---
title: "Lecture 07: Markov Chain Monte Carlo"
author: "Chun-Hao Yang"
footer: "[Home](https://chunhaoy.com/stat-5010/)"
format: 
    revealjs:
        theme: slides.scss
        chalkboard: true
        slide-number: true
        html-math-method: mathjax
        incremental: true
        scrollable: true
execute:
    echo: false
    warning: false
    cache: true
    freeze: auto
---

## Motivation 

-   We have seen that in many cases, the posterior is only available upto a normalizing constant.
-   To compute the posterior mean, we need to numerically (i) compute the normalizing constant and (ii) compute the posterior mean.
-   Numerical integration in high dimension is very difficult and we will resort to Monte Carlo methods, which use random numbers to compute/approximate the integral.
-   The idea is to generate a large number of (iid) random samples from the posterior distribution and use the sample mean as an approximation to the posterior mean.
-   There are a few questions:
    +   how to generate iid random samples from an arbitrary distribution?
    +   how to do it without knowing the normalizing constant?

## Markov Chain Monte Carlo (MCMC)

-   MCMC uses samples from a Markov chain whose stationary distribution is the target distribution.
-   Hence the samples are **not** independent and **not** from the target distribution.
-   They are only [iid from the target distribution]{.underline} asymptotically.
-   The problem is now how to construct a Markov chain whose stationary distribution is the posterior.
-   We will introduce three algorithms:
    +   Gibbs sampler
    +   Metropolis-Hastings algorithm
    +   Hamiltonian Monte Carlo (HMC)

# Gibbs Sampler

## Gibbs Sampler

-   Consider a parameter vector $\theta = (\theta_1, \theta_2, \ldots, \theta_p)$ with posterior $\pi(\theta|y)$.
-   If we can sample from the full conditional distributions $\pi(\theta_i|\theta_{-i}, y)$, then we can construct a Markov chain whose stationary distribution is the posterior.
-   Algorithm:
    +   Initialize $\theta^{(0)} = (\theta_1^{(0)}, \theta_2^{(0)}, \ldots, \theta_p^{(0)})$.
    +   For $t = 1, 2, \ldots, T$:
        1.  Sample $\theta_1^{(t)} \sim \pi(\theta_1|\theta_2^{(t-1)}, \theta_3^{(t-1)}, \ldots, \theta_p^{(t-1)}, y)$.
        2.  Sample $\theta_j^{(t)} \sim \pi(\theta_2|\theta_1^{(t)}, \ldots, \theta_{j-1}^{(t)}, \theta_{j+1}^{(t-1)}, \ldots, \theta_p^{(t-1)}, y)$.
    +   Return $\theta^{(1)}, \theta^{(2)}, \ldots, \theta^{(T)}$.
    
## Example: Bivariate Normal

-   Suppose we want to generate samples from a bivariate normal with mean $\mu = (\mu_1, \mu_2)$ and covariance matrix $\Sigma$.
-   Let $[X_1, X_2]^T \sim N(\mu, \Sigma)$. The full conditionals are:
    +   $X_1|X_2 \sim N(\mu_1 + \Sigma_{12}\Sigma_{22}^{-1}(X_2 - \mu_2), \Sigma_{11} - \Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21})$.
    +   $X_2|X_1 \sim N(\mu_2 + \Sigma_{21}\Sigma_{11}^{-1}(X_1 - \mu_1), \Sigma_{22} - \Sigma_{21}\Sigma_{11}^{-1}\Sigma_{12})$.
    
:::{.fragment}

```{r}
#| echo: true
# initialize
mu <- c(0, 0)
Sigma <- matrix(c(1, 0.5, 0.5, 1), nrow = 2)
X <- matrix(0, nrow = 2, ncol = 1000)

# Gibbs sampler
for (t in 2:1000) {
    X[1, t] <- rnorm(1, mu[1] + Sigma[1, 2] / Sigma[2, 2] * (X[2, t-1] - mu[2]), 
                     sqrt(Sigma[1, 1] - Sigma[1, 2] / Sigma[2, 2] * Sigma[2, 1]))
    X[2, t] <- rnorm(1, mu[2] + Sigma[2, 1] / Sigma[1, 1] * (X[1, t] - mu[1]), 
                     sqrt(Sigma[2, 2] - Sigma[2, 1] / Sigma[1, 1] * Sigma[1, 2]))
}

```

:::
## Checking Convergence

```{r}
#| echo: true
# trace plot
par(mfrow = c(1,2))
plot(X[1, ], type = "l", ylab = expression(X[1]), xlab = "Iteration")
plot(X[2, ], type = "l", ylab = expression(X[2]), xlab = "Iteration")
```

## Checking Convergence
```{r}
#| echo: true
# contour plot
par(mfrow = c(1,2))
plot(X[1, ], X[2, ], xlab = expression(X[1]), ylab = expression(X[2]))
```

## When to use Gibbs sampler?




# Metropolis-Hastings Algorithm

## Metropolis Algorithm

## Metropolis-Hastings Algorithm

# Diagnostic of MCMC

## Diagnostic of MCMC samples



-   convergence
-   mixing
-   autocorrelation
-   effective sample size
-   burn-in
-   thinning
-   autocorrelation time


## Example

